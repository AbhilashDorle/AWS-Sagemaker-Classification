{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to run Logistic regression on Adult dataset\n",
    "### write information about Adult dataset from UCI repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-east-2 region. You will use the 825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "\n",
    "# Define IAM role and XGBoost (remove after carefully analysing the code)\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 error:  An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'big-data-1' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "      s3.create_bucket(Bucket=bucket_name)\n",
    "    else: \n",
    "      s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  train_data = pd.read_csv('adult_df.csv')\n",
    "  print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "      <th>hours_w</th>\n",
       "      <th>native_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>between_40_and_45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass  fnlwgt   education  education_num  marital_status  \\\n",
       "0   39   State-gov   77516   Bachelors             13   Never-married   \n",
       "\n",
       "      occupation    relationship    race    sex  capital_gain  capital_loss  \\\n",
       "0   Adm-clerical   Not-in-family   White   Male          2174             0   \n",
       "\n",
       "   hours_per_week  native_country  income             hours_w   native_region  \n",
       "0              40   United-States   <=50K   between_40_and_45   United-States  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Test Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  model_data = pd.read_csv('test_df.csv')\n",
    "  print('Success: Test Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "      <th>hours_w</th>\n",
       "      <th>native_region</th>\n",
       "      <th>cap_gain</th>\n",
       "      <th>cap_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>between_40_and_45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>between_45_and_60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt education  education_num       marital_status  \\\n",
       "0   25   Private  226802      11th              7        Never-married   \n",
       "1   38   Private   89814   HS-grad              9   Married-civ-spouse   \n",
       "\n",
       "           occupation relationship    race    sex  capital_gain  capital_loss  \\\n",
       "0   Machine-op-inspct    Own-child   Black   Male             0             0   \n",
       "1     Farming-fishing      Husband   White   Male             0             0   \n",
       "\n",
       "   hours_per_week  native_country  income             hours_w   native_region  \\\n",
       "0              40   United-States   <=50K   between_40_and_45   United-States   \n",
       "1              50   United-States   <=50K   between_45_and_60   United-States   \n",
       "\n",
       "  cap_gain cap_loss  \n",
       "0      Low      Low  \n",
       "1      Low      Low  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating dummy values for Train data\n",
    "### Developing labels: '0' = <=50K, '1' = >50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data, columns=[\n",
    "    \"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\",\n",
    "    \"race\", \"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 67)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=train_data['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.drop(columns=['income','hours_w','native_region', \"native_country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 63)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=label[0]\n",
    "labels=[]\n",
    "for i in label:\n",
    "    if i ==temp:\n",
    "        labels.append(0)#<=50K\n",
    "    else:\n",
    "        labels.append(1)\n",
    "labels=np.array(labels).astype('float32')\n",
    "train_data=np.array(train_data).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating dummy values for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.get_dummies(model_data, columns=[\n",
    "    \"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\",\n",
    "    \"race\", \"sex\"])\n",
    "test_label=model_data['income']\n",
    "model_data=model_data.drop(columns=['income','hours_w','native_region','cap_gain','cap_loss',\"native_country\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 63)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data=np.array(model_data).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.amazon.common as smac\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.BytesIO'>\n",
      "upoaded training data location : s3://big-data-1/sagemaker/Income/train/linearlearner\n",
      "training artifacts will be uploaded to : s3://big-data-1/sagemaker/Income/output\n"
     ]
    }
   ],
   "source": [
    "key='linearlearner'\n",
    "sess=sagemaker.Session()\n",
    "prefix=\"sagemaker/Income\"\n",
    "buf=io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf,train_data,labels)\n",
    "buf.seek(0)\n",
    "print(type(buf))\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train',key)).upload_fileobj(buf)\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket_name,prefix,key)\n",
    "#sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')\n",
    "print('upoaded training data location : {}'.format(s3_train_data))\n",
    "output_location='s3://{}/{}/output'.format(bucket_name,prefix)\n",
    "print('training artifacts will be uploaded to : {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE THIS IF XGBOSST IS NOT REQUIRED \n",
    "# sess = sagemaker.Session()\n",
    "# xgb = sagemaker.estimator.Estimator(containers[my_region],role, train_instance_count=1, train_instance_type='ml.m4.xlarge',output_path='s3://{}/{}/output'.format(bucket_name, prefix),sagemaker_session=sess)\n",
    "# xgb.set_hyperparameters(max_depth=5,eta=0.2,gamma=4,min_child_weight=6,subsample=0.8,silent=0,objective='binary:logistic',num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = {'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/linear-learner:latest',\n",
    "              'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:latest',\n",
    "              'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/linear-learner:latest',\n",
    "              'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/linear-learner:latest',\n",
    "              'ap-northeast-1': '351501993468.dkr.ecr.ap-northeast-1.amazonaws.com/linear-learner:latest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'404615174143.dkr.ecr.us-east-2.amazonaws.com/linear-learner:latest'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containers[boto3.Session().region_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "linear = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.c4.xlarge',\n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.set_hyperparameters(feature_dim=63,\n",
    "                           predictor_type='binary_classifier',loss='hinge_loss', \n",
    "                           normalize_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-10 16:35:43 Starting - Starting the training job...\n",
      "2019-12-10 16:35:44 Starting - Launching requested ML instances...\n",
      "2019-12-10 16:36:39 Starting - Preparing the instances for training......\n",
      "2019-12-10 16:37:32 Downloading - Downloading input data...\n",
      "2019-12-10 16:38:14 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 INFO 139764330137408] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'auto', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 INFO 139764330137408] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'normalize_data': u'False', u'loss': u'hinge_loss', u'feature_dim': u'63', u'predictor_type': u'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 INFO 139764330137408] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'63', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'False', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'predictor_type': u'binary_classifier', u'beta_1': u'auto', u'loss': u'hinge_loss', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 WARNING 139764330137408] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 INFO 139764330137408] Using default worker.\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:17.197] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 21, \"num_examples\": 1, \"num_bytes\": 300000}\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 INFO 139764330137408] Create Store: local\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:17.244] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 46, \"num_examples\": 11, \"num_bytes\": 3300000}\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 INFO 139764330137408] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f1d1d714050>\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 INFO 139764330137408] Scaling model computed with parameters:\n",
      " {'stdev_weight': None, 'stdev_label': None, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[3.83299103e+01 1.90351391e+05 1.01167269e+01 1.07658667e+03\n",
      " 8.97439957e+01 4.10524559e+01 2.99999993e-02 6.79090917e-02\n",
      " 7.38545477e-01 3.59999985e-02 8.31818208e-02 4.41818163e-02\n",
      " 1.81818177e-04 2.80000009e-02 3.47272716e-02 1.03636375e-02\n",
      " 4.63636313e-03 8.81818309e-03 1.85454544e-02 1.48181822e-02\n",
      " 3.18181813e-02 4.12727259e-02 1.67454541e-01 1.12727275e-02\n",
      " 3.28545451e-01 5.40000014e-02 1.36363634e-03 1.75454542e-02\n",
      " 2.26818189e-01 1.41545460e-01 6.36363693e-04 4.65909094e-01\n",
      " 1.25454543e-02 3.21181804e-01 3.25454548e-02 2.56363638e-02\n",
      " 1.27363637e-01 1.81818177e-04 1.30272731e-01 1.29818186e-01\n",
      " 3.17272730e-02 4.29090932e-02 6.54545426e-02 1.09181821e-01\n",
      " 4.81818151e-03 1.32090911e-01 2.17272732e-02 1.21545456e-01\n",
      " 2.99999993e-02 5.29090911e-02 4.11727279e-01 2.59090900e-01\n",
      " 2.86363643e-02 1.46272719e-01 1.06090911e-01 4.81818169e-02\n",
      " 9.45454556e-03 2.89090909e-02 9.45454538e-02 7.09090894e-03\n",
      " 8.60000014e-01 3.21272731e-01 6.78727269e-01]\u001b[0m\n",
      "\u001b[34m<NDArray 63 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 INFO 139764330137408] nvidia-smi took: 0.0252149105072 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:17 INFO 139764330137408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Total Records Seen\": {\"count\": 1, \"max\": 12000, \"sum\": 12000.0, \"min\": 12000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11000, \"sum\": 11000.0, \"min\": 11000}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1575995897.390469, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1575995897.390433}\n",
      "\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:18.299] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 908, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 79.23721516927084, \"sum\": 79.23721516927084, \"min\": 79.23721516927084}}, \"EndTime\": 1575995898.299636, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.299542}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 206.39779342447918, \"sum\": 206.39779342447918, \"min\": 206.39779342447918}}, \"EndTime\": 1575995898.299716, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.299698}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 709.710018359375, \"sum\": 709.710018359375, \"min\": 709.710018359375}}, \"EndTime\": 1575995898.299785, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.299768}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 99.69088193359374, \"sum\": 99.69088193359374, \"min\": 99.69088193359374}}, \"EndTime\": 1575995898.29986, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.299841}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 784.955434375, \"sum\": 784.955434375, \"min\": 784.955434375}}, \"EndTime\": 1575995898.299932, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.299914}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 777.0212322916667, \"sum\": 777.0212322916667, \"min\": 777.0212322916667}}, \"EndTime\": 1575995898.3, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.299983}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 776.843021875, \"sum\": 776.843021875, \"min\": 776.843021875}}, \"EndTime\": 1575995898.300068, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.30005}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 765.7289140625, \"sum\": 765.7289140625, \"min\": 765.7289140625}}, \"EndTime\": 1575995898.300123, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300107}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 42.6412314453125, \"sum\": 42.6412314453125, \"min\": 42.6412314453125}}, \"EndTime\": 1575995898.300177, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300162}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 201.87965026041667, \"sum\": 201.87965026041667, \"min\": 201.87965026041667}}, \"EndTime\": 1575995898.300236, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300219}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 63.95242184244792, \"sum\": 63.95242184244792, \"min\": 63.95242184244792}}, \"EndTime\": 1575995898.300304, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300286}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 338.26800611979166, \"sum\": 338.26800611979166, \"min\": 338.26800611979166}}, \"EndTime\": 1575995898.30037, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300352}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 991.2426244791667, \"sum\": 991.2426244791667, \"min\": 991.2426244791667}}, \"EndTime\": 1575995898.300441, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300422}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 737.9473572916667, \"sum\": 737.9473572916667, \"min\": 737.9473572916667}}, \"EndTime\": 1575995898.300509, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300492}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 786.7026479166667, \"sum\": 786.7026479166667, \"min\": 786.7026479166667}}, \"EndTime\": 1575995898.30057, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300553}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 652.2080950520833, \"sum\": 652.2080950520833, \"min\": 652.2080950520833}}, \"EndTime\": 1575995898.300626, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.30061}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 540.2325958984375, \"sum\": 540.2325958984375, \"min\": 540.2325958984375}}, \"EndTime\": 1575995898.300684, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300667}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 287.7571349283854, \"sum\": 287.7571349283854, \"min\": 287.7571349283854}}, \"EndTime\": 1575995898.300743, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300727}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 170.48324899088541, \"sum\": 170.48324899088541, \"min\": 170.48324899088541}}, \"EndTime\": 1575995898.300801, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300785}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 47.84207724609375, \"sum\": 47.84207724609375, \"min\": 47.84207724609375}}, \"EndTime\": 1575995898.300861, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300844}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 1091.322825065104, \"sum\": 1091.322825065104, \"min\": 1091.322825065104}}, \"EndTime\": 1575995898.300918, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300902}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 382.94175286458335, \"sum\": 382.94175286458335, \"min\": 382.94175286458335}}, \"EndTime\": 1575995898.300958, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.300949}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 778.2817234375, \"sum\": 778.2817234375, \"min\": 778.2817234375}}, \"EndTime\": 1575995898.301017, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.301001}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 761.9897927083333, \"sum\": 761.9897927083333, \"min\": 761.9897927083333}}, \"EndTime\": 1575995898.301065, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.30105}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 159.12511575520833, \"sum\": 159.12511575520833, \"min\": 159.12511575520833}}, \"EndTime\": 1575995898.301123, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.301107}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 91.87313671875, \"sum\": 91.87313671875, \"min\": 91.87313671875}}, \"EndTime\": 1575995898.301181, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.301165}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 240.55021393229165, \"sum\": 240.55021393229165, \"min\": 240.55021393229165}}, \"EndTime\": 1575995898.301238, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.301221}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 783.8400899088541, \"sum\": 783.8400899088541, \"min\": 783.8400899088541}}, \"EndTime\": 1575995898.301294, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.301278}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 435.9217888020833, \"sum\": 435.9217888020833, \"min\": 435.9217888020833}}, \"EndTime\": 1575995898.301337, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.301327}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 677.7693932291667, \"sum\": 677.7693932291667, \"min\": 677.7693932291667}}, \"EndTime\": 1575995898.301372, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.301359}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 752.8216015625, \"sum\": 752.8216015625, \"min\": 752.8216015625}}, \"EndTime\": 1575995898.301427, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.301411}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 709.6961130208333, \"sum\": 709.6961130208333, \"min\": 709.6961130208333}}, \"EndTime\": 1575995898.301466, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995898.301457}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:18 INFO 139764330137408] #quality_metric: host=algo-1, epoch=0, train binary_classification_hinge_loss_objective <loss>=79.2372151693\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:18 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_hinge_loss_objective, value=42.6412314453\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:18 INFO 139764330137408] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:18 INFO 139764330137408] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}, \"Total Records Seen\": {\"count\": 1, \"max\": 42162, \"sum\": 42162.0, \"min\": 42162}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1575995898.304643, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1575995897.390658}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:18 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=32995.9190207 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:19.513] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 1208, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 12.523593221028646, \"sum\": 12.523593221028646, \"min\": 12.523593221028646}}, \"EndTime\": 1575995899.513927, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.513816}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 27.822242805989582, \"sum\": 27.822242805989582, \"min\": 27.822242805989582}}, \"EndTime\": 1575995899.514025, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514003}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 75.63225872395833, \"sum\": 75.63225872395833, \"min\": 75.63225872395833}}, \"EndTime\": 1575995899.514093, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514074}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 19.215557486979165, \"sum\": 19.215557486979165, \"min\": 19.215557486979165}}, \"EndTime\": 1575995899.514156, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514137}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 200.60453541666666, \"sum\": 200.60453541666666, \"min\": 200.60453541666666}}, \"EndTime\": 1575995899.514219, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.5142}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 297.164692578125, \"sum\": 297.164692578125, \"min\": 297.164692578125}}, \"EndTime\": 1575995899.514281, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514263}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 188.76032278645835, \"sum\": 188.76032278645835, \"min\": 188.76032278645835}}, \"EndTime\": 1575995899.514342, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514325}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 165.463562890625, \"sum\": 165.463562890625, \"min\": 165.463562890625}}, \"EndTime\": 1575995899.514401, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514384}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.494567134602864, \"sum\": 10.494567134602864, \"min\": 10.494567134602864}}, \"EndTime\": 1575995899.514459, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514443}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 18.957482861328124, \"sum\": 18.957482861328124, \"min\": 18.957482861328124}}, \"EndTime\": 1575995899.514518, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514501}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 12.638316178385416, \"sum\": 12.638316178385416, \"min\": 12.638316178385416}}, \"EndTime\": 1575995899.514577, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.51456}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 45.09352252604167, \"sum\": 45.09352252604167, \"min\": 45.09352252604167}}, \"EndTime\": 1575995899.514637, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.51462}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 251.89541744791666, \"sum\": 251.89541744791666, \"min\": 251.89541744791666}}, \"EndTime\": 1575995899.514694, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514678}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 169.72086861979167, \"sum\": 169.72086861979167, \"min\": 169.72086861979167}}, \"EndTime\": 1575995899.514749, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514734}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 179.38781243489584, \"sum\": 179.38781243489584, \"min\": 179.38781243489584}}, \"EndTime\": 1575995899.514805, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.51479}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 186.77916276041665, \"sum\": 186.77916276041665, \"min\": 186.77916276041665}}, \"EndTime\": 1575995899.514858, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514843}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 47.27492428385417, \"sum\": 47.27492428385417, \"min\": 47.27492428385417}}, \"EndTime\": 1575995899.514918, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514901}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 26.04962529296875, \"sum\": 26.04962529296875, \"min\": 26.04962529296875}}, \"EndTime\": 1575995899.514978, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.514961}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 19.030921256510418, \"sum\": 19.030921256510418, \"min\": 19.030921256510418}}, \"EndTime\": 1575995899.515035, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515019}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.585171044921875, \"sum\": 10.585171044921875, \"min\": 10.585171044921875}}, \"EndTime\": 1575995899.515147, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515126}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 246.14704290364583, \"sum\": 246.14704290364583, \"min\": 246.14704290364583}}, \"EndTime\": 1575995899.515205, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515189}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 156.596617578125, \"sum\": 156.596617578125, \"min\": 156.596617578125}}, \"EndTime\": 1575995899.515263, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515245}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 195.68067734375, \"sum\": 195.68067734375, \"min\": 195.68067734375}}, \"EndTime\": 1575995899.515322, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515306}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 342.11990221354165, \"sum\": 342.11990221354165, \"min\": 342.11990221354165}}, \"EndTime\": 1575995899.515379, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515363}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 21.295219010416666, \"sum\": 21.295219010416666, \"min\": 21.295219010416666}}, \"EndTime\": 1575995899.515472, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515454}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 16.216344014485678, \"sum\": 16.216344014485678, \"min\": 16.216344014485678}}, \"EndTime\": 1575995899.515529, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515512}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 32.40536881510417, \"sum\": 32.40536881510417, \"min\": 32.40536881510417}}, \"EndTime\": 1575995899.515585, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515569}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 60.7136109375, \"sum\": 60.7136109375, \"min\": 60.7136109375}}, \"EndTime\": 1575995899.515642, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515625}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 252.34391796875, \"sum\": 252.34391796875, \"min\": 252.34391796875}}, \"EndTime\": 1575995899.515701, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515683}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 148.28700559895833, \"sum\": 148.28700559895833, \"min\": 148.28700559895833}}, \"EndTime\": 1575995899.51576, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515743}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 146.692909375, \"sum\": 146.692909375, \"min\": 146.692909375}}, \"EndTime\": 1575995899.515817, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.5158}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 170.90539765625, \"sum\": 170.90539765625, \"min\": 170.90539765625}}, \"EndTime\": 1575995899.515875, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995899.515859}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:19 INFO 139764330137408] #quality_metric: host=algo-1, epoch=1, train binary_classification_hinge_loss_objective <loss>=12.523593221\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:19 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=binary_classification_hinge_loss_objective, value=10.4945671346\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:19 INFO 139764330137408] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:19 INFO 139764330137408] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 74, \"sum\": 74.0, \"min\": 74}, \"Total Records Seen\": {\"count\": 1, \"max\": 72324, \"sum\": 72324.0, \"min\": 72324}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1575995899.520141, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1575995898.305268}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:19 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=24824.5518439 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:20.635] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 1114, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.234466438802084, \"sum\": 8.234466438802084, \"min\": 8.234466438802084}}, \"EndTime\": 1575995900.635637, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.635533}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 17.114618717447918, \"sum\": 17.114618717447918, \"min\": 17.114618717447918}}, \"EndTime\": 1575995900.635726, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.635707}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 21.33195086669922, \"sum\": 21.33195086669922, \"min\": 21.33195086669922}}, \"EndTime\": 1575995900.635793, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.635775}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.349084147135416, \"sum\": 7.349084147135416, \"min\": 7.349084147135416}}, \"EndTime\": 1575995900.635857, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.635838}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 114.52847239583333, \"sum\": 114.52847239583333, \"min\": 114.52847239583333}}, \"EndTime\": 1575995900.635919, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.635901}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 223.85945345052085, \"sum\": 223.85945345052085, \"min\": 223.85945345052085}}, \"EndTime\": 1575995900.635988, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.635969}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 139.34104954427085, \"sum\": 139.34104954427085, \"min\": 139.34104954427085}}, \"EndTime\": 1575995900.636058, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.63604}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 485.38597239583333, \"sum\": 485.38597239583333, \"min\": 485.38597239583333}}, \"EndTime\": 1575995900.636126, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636107}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 21.884467268880208, \"sum\": 21.884467268880208, \"min\": 21.884467268880208}}, \"EndTime\": 1575995900.636188, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636171}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 9.271528515625, \"sum\": 9.271528515625, \"min\": 9.271528515625}}, \"EndTime\": 1575995900.636255, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636237}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.89623828125, \"sum\": 5.89623828125, \"min\": 5.89623828125}}, \"EndTime\": 1575995900.636315, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636298}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 17.935361360677085, \"sum\": 17.935361360677085, \"min\": 17.935361360677085}}, \"EndTime\": 1575995900.636384, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636366}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 158.5457935546875, \"sum\": 158.5457935546875, \"min\": 158.5457935546875}}, \"EndTime\": 1575995900.636453, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636435}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 161.9870208984375, \"sum\": 161.9870208984375, \"min\": 161.9870208984375}}, \"EndTime\": 1575995900.636513, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636497}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 143.79967578125, \"sum\": 143.79967578125, \"min\": 143.79967578125}}, \"EndTime\": 1575995900.636574, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636558}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 299.3024868489583, \"sum\": 299.3024868489583, \"min\": 299.3024868489583}}, \"EndTime\": 1575995900.636638, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.63662}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 14.165501570638021, \"sum\": 14.165501570638021, \"min\": 14.165501570638021}}, \"EndTime\": 1575995900.6367, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636682}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.196477799479167, \"sum\": 10.196477799479167, \"min\": 10.196477799479167}}, \"EndTime\": 1575995900.636762, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636745}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.021780338541666, \"sum\": 6.021780338541666, \"min\": 6.021780338541666}}, \"EndTime\": 1575995900.636823, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636804}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.9173275390625, \"sum\": 7.9173275390625, \"min\": 7.9173275390625}}, \"EndTime\": 1575995900.636883, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636866}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 250.61936041666667, \"sum\": 250.61936041666667, \"min\": 250.61936041666667}}, \"EndTime\": 1575995900.636949, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.63693}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 157.64924560546876, \"sum\": 157.64924560546876, \"min\": 157.64924560546876}}, \"EndTime\": 1575995900.637016, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.636998}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 245.45717994791667, \"sum\": 245.45717994791667, \"min\": 245.45717994791667}}, \"EndTime\": 1575995900.637083, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637065}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 248.09336276041665, \"sum\": 248.09336276041665, \"min\": 248.09336276041665}}, \"EndTime\": 1575995900.637151, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637133}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 9.679359602864583, \"sum\": 9.679359602864583, \"min\": 9.679359602864583}}, \"EndTime\": 1575995900.637217, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637199}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.507645271809896, \"sum\": 7.507645271809896, \"min\": 7.507645271809896}}, \"EndTime\": 1575995900.637278, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637261}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.599953377278645, \"sum\": 10.599953377278645, \"min\": 10.599953377278645}}, \"EndTime\": 1575995900.637341, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637325}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 15.21037138671875, \"sum\": 15.21037138671875, \"min\": 15.21037138671875}}, \"EndTime\": 1575995900.637404, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637388}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 252.4020068359375, \"sum\": 252.4020068359375, \"min\": 252.4020068359375}}, \"EndTime\": 1575995900.637472, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637454}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 233.07906139322915, \"sum\": 233.07906139322915, \"min\": 233.07906139322915}}, \"EndTime\": 1575995900.637532, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637515}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 139.408197265625, \"sum\": 139.408197265625, \"min\": 139.408197265625}}, \"EndTime\": 1575995900.637589, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637572}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 424.93450390625, \"sum\": 424.93450390625, \"min\": 424.93450390625}}, \"EndTime\": 1575995900.637647, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995900.637632}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:20 INFO 139764330137408] #quality_metric: host=algo-1, epoch=2, train binary_classification_hinge_loss_objective <loss>=8.2344664388\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:20 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=binary_classification_hinge_loss_objective, value=5.89623828125\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:20 INFO 139764330137408] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:20 INFO 139764330137408] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 105, \"sum\": 105.0, \"min\": 105}, \"Total Records Seen\": {\"count\": 1, \"max\": 102486, \"sum\": 102486.0, \"min\": 102486}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1575995900.640409, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1575995899.52093}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:20 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=26939.185514 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:21.579] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 937, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.366526021321614, \"sum\": 4.366526021321614, \"min\": 4.366526021321614}}, \"EndTime\": 1575995901.579166, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.57907}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.037414241536458, \"sum\": 10.037414241536458, \"min\": 10.037414241536458}}, \"EndTime\": 1575995901.579251, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579233}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.062532666015625, \"sum\": 6.062532666015625, \"min\": 6.062532666015625}}, \"EndTime\": 1575995901.579311, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579295}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.3827811665852865, \"sum\": 4.3827811665852865, \"min\": 4.3827811665852865}}, \"EndTime\": 1575995901.579364, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579348}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 228.93252337239582, \"sum\": 228.93252337239582, \"min\": 228.93252337239582}}, \"EndTime\": 1575995901.579455, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579435}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 146.23679817708333, \"sum\": 146.23679817708333, \"min\": 146.23679817708333}}, \"EndTime\": 1575995901.579517, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579499}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 133.59981653645832, \"sum\": 133.59981653645832, \"min\": 133.59981653645832}}, \"EndTime\": 1575995901.579577, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.57956}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 220.35687669270834, \"sum\": 220.35687669270834, \"min\": 220.35687669270834}}, \"EndTime\": 1575995901.579637, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579619}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.907850651041667, \"sum\": 7.907850651041667, \"min\": 7.907850651041667}}, \"EndTime\": 1575995901.579692, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579676}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.765961971028646, \"sum\": 7.765961971028646, \"min\": 7.765961971028646}}, \"EndTime\": 1575995901.57976, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579741}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.066973173014323, \"sum\": 6.066973173014323, \"min\": 6.066973173014323}}, \"EndTime\": 1575995901.579829, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579811}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.143101611328126, \"sum\": 10.143101611328126, \"min\": 10.143101611328126}}, \"EndTime\": 1575995901.579896, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579878}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 165.418448046875, \"sum\": 165.418448046875, \"min\": 165.418448046875}}, \"EndTime\": 1575995901.579964, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.579947}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 266.24042369791664, \"sum\": 266.24042369791664, \"min\": 266.24042369791664}}, \"EndTime\": 1575995901.580033, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580014}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 148.73336373697916, \"sum\": 148.73336373697916, \"min\": 148.73336373697916}}, \"EndTime\": 1575995901.580102, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580084}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 241.35554544270835, \"sum\": 241.35554544270835, \"min\": 241.35554544270835}}, \"EndTime\": 1575995901.580161, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580144}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.430925703938802, \"sum\": 7.430925703938802, \"min\": 7.430925703938802}}, \"EndTime\": 1575995901.58023, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580212}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.890340543619792, \"sum\": 7.890340543619792, \"min\": 7.890340543619792}}, \"EndTime\": 1575995901.580299, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580281}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.554709733072917, \"sum\": 5.554709733072917, \"min\": 5.554709733072917}}, \"EndTime\": 1575995901.580366, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580348}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.041605696614583, \"sum\": 8.041605696614583, \"min\": 8.041605696614583}}, \"EndTime\": 1575995901.580434, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580416}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 222.26359723307291, \"sum\": 222.26359723307291, \"min\": 222.26359723307291}}, \"EndTime\": 1575995901.580487, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580474}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 175.31734895833333, \"sum\": 175.31734895833333, \"min\": 175.31734895833333}}, \"EndTime\": 1575995901.580542, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580527}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 132.54377421875, \"sum\": 132.54377421875, \"min\": 132.54377421875}}, \"EndTime\": 1575995901.580592, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580577}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 174.80964609375, \"sum\": 174.80964609375, \"min\": 174.80964609375}}, \"EndTime\": 1575995901.580645, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580631}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.791502608235677, \"sum\": 4.791502608235677, \"min\": 4.791502608235677}}, \"EndTime\": 1575995901.580699, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580685}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.403912795003255, \"sum\": 4.403912795003255, \"min\": 4.403912795003255}}, \"EndTime\": 1575995901.580748, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580732}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.554424617513021, \"sum\": 4.554424617513021, \"min\": 4.554424617513021}}, \"EndTime\": 1575995901.580801, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580788}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 11.865026542154949, \"sum\": 11.865026542154949, \"min\": 11.865026542154949}}, \"EndTime\": 1575995901.580865, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580848}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 221.813670703125, \"sum\": 221.813670703125, \"min\": 221.813670703125}}, \"EndTime\": 1575995901.58092, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580906}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 175.68369505208332, \"sum\": 175.68369505208332, \"min\": 175.68369505208332}}, \"EndTime\": 1575995901.580956, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.580943}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 257.5339768554687, \"sum\": 257.5339768554687, \"min\": 257.5339768554687}}, \"EndTime\": 1575995901.581021, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.581004}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 167.8254498046875, \"sum\": 167.8254498046875, \"min\": 167.8254498046875}}, \"EndTime\": 1575995901.581085, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995901.581068}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:21 INFO 139764330137408] #quality_metric: host=algo-1, epoch=3, train binary_classification_hinge_loss_objective <loss>=4.36652602132\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:21 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=binary_classification_hinge_loss_objective, value=4.36652602132\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:21 INFO 139764330137408] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:21 INFO 139764330137408] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 136, \"sum\": 136.0, \"min\": 136}, \"Total Records Seen\": {\"count\": 1, \"max\": 132648, \"sum\": 132648.0, \"min\": 132648}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1575995901.583812, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1575995900.640998}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:21 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=31987.2214673 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:22.536] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 951, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.460359193929037, \"sum\": 4.460359193929037, \"min\": 4.460359193929037}}, \"EndTime\": 1575995902.536196, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536093}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.211796598307291, \"sum\": 7.211796598307291, \"min\": 7.211796598307291}}, \"EndTime\": 1575995902.536287, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536267}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.4731047932942705, \"sum\": 5.4731047932942705, \"min\": 5.4731047932942705}}, \"EndTime\": 1575995902.536355, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536336}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.373931227620442, \"sum\": 4.373931227620442, \"min\": 4.373931227620442}}, \"EndTime\": 1575995902.536418, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536402}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 143.78714765625, \"sum\": 143.78714765625, \"min\": 143.78714765625}}, \"EndTime\": 1575995902.536473, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536456}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 87.01385234375, \"sum\": 87.01385234375, \"min\": 87.01385234375}}, \"EndTime\": 1575995902.536531, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536514}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 109.11888489583333, \"sum\": 109.11888489583333, \"min\": 109.11888489583333}}, \"EndTime\": 1575995902.53659, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536573}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 137.72092044270832, \"sum\": 137.72092044270832, \"min\": 137.72092044270832}}, \"EndTime\": 1575995902.536649, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536632}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.435294807942708, \"sum\": 6.435294807942708, \"min\": 6.435294807942708}}, \"EndTime\": 1575995902.536707, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536691}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.3287082845052085, \"sum\": 7.3287082845052085, \"min\": 7.3287082845052085}}, \"EndTime\": 1575995902.536762, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536745}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.707015309651693, \"sum\": 3.707015309651693, \"min\": 3.707015309651693}}, \"EndTime\": 1575995902.536821, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536803}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 9.404475447591146, \"sum\": 9.404475447591146, \"min\": 9.404475447591146}}, \"EndTime\": 1575995902.536879, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536861}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 88.06250208333333, \"sum\": 88.06250208333333, \"min\": 88.06250208333333}}, \"EndTime\": 1575995902.536936, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.53692}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 144.22513125, \"sum\": 144.22513125, \"min\": 144.22513125}}, \"EndTime\": 1575995902.536992, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.536976}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 165.09943268229168, \"sum\": 165.09943268229168, \"min\": 165.09943268229168}}, \"EndTime\": 1575995902.537047, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537029}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 133.71274694010415, \"sum\": 133.71274694010415, \"min\": 133.71274694010415}}, \"EndTime\": 1575995902.537105, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537088}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 11.03454375, \"sum\": 11.03454375, \"min\": 11.03454375}}, \"EndTime\": 1575995902.537165, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537147}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 9.068879353841146, \"sum\": 9.068879353841146, \"min\": 9.068879353841146}}, \"EndTime\": 1575995902.537223, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537207}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.584530029296875, \"sum\": 8.584530029296875, \"min\": 8.584530029296875}}, \"EndTime\": 1575995902.53728, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537264}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.930723461914062, \"sum\": 6.930723461914062, \"min\": 6.930723461914062}}, \"EndTime\": 1575995902.537337, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537321}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 278.4287936197917, \"sum\": 278.4287936197917, \"min\": 278.4287936197917}}, \"EndTime\": 1575995902.537395, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537378}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 158.52917428385416, \"sum\": 158.52917428385416, \"min\": 158.52917428385416}}, \"EndTime\": 1575995902.537453, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537437}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 122.40919427083334, \"sum\": 122.40919427083334, \"min\": 122.40919427083334}}, \"EndTime\": 1575995902.53751, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537494}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 130.732821484375, \"sum\": 130.732821484375, \"min\": 130.732821484375}}, \"EndTime\": 1575995902.537567, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537551}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.9392396809895835, \"sum\": 7.9392396809895835, \"min\": 7.9392396809895835}}, \"EndTime\": 1575995902.53763, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537613}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 13.47769383951823, \"sum\": 13.47769383951823, \"min\": 13.47769383951823}}, \"EndTime\": 1575995902.537695, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537677}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.434309818522136, \"sum\": 10.434309818522136, \"min\": 10.434309818522136}}, \"EndTime\": 1575995902.537749, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537733}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 13.740856555175782, \"sum\": 13.740856555175782, \"min\": 13.740856555175782}}, \"EndTime\": 1575995902.537805, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537789}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 113.02419635416666, \"sum\": 113.02419635416666, \"min\": 113.02419635416666}}, \"EndTime\": 1575995902.537862, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537846}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 167.9340828125, \"sum\": 167.9340828125, \"min\": 167.9340828125}}, \"EndTime\": 1575995902.537917, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537902}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 136.18116861979166, \"sum\": 136.18116861979166, \"min\": 136.18116861979166}}, \"EndTime\": 1575995902.537974, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.537957}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 175.04764388020834, \"sum\": 175.04764388020834, \"min\": 175.04764388020834}}, \"EndTime\": 1575995902.538032, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995902.538015}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:22 INFO 139764330137408] #quality_metric: host=algo-1, epoch=4, train binary_classification_hinge_loss_objective <loss>=4.46035919393\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:22 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=binary_classification_hinge_loss_objective, value=3.70701530965\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:22 INFO 139764330137408] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:22 INFO 139764330137408] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 167, \"sum\": 167.0, \"min\": 167}, \"Total Records Seen\": {\"count\": 1, \"max\": 162810, \"sum\": 162810.0, \"min\": 162810}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1575995902.540725, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1575995901.584409}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:22 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=31535.9237685 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:23.490] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 948, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.297705843098958, \"sum\": 6.297705843098958, \"min\": 6.297705843098958}}, \"EndTime\": 1575995903.490334, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490235}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.9806524943033854, \"sum\": 3.9806524943033854, \"min\": 3.9806524943033854}}, \"EndTime\": 1575995903.490412, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490395}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.983435070800781, \"sum\": 4.983435070800781, \"min\": 4.983435070800781}}, \"EndTime\": 1575995903.490478, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490459}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.1875015787760415, \"sum\": 7.1875015787760415, \"min\": 7.1875015787760415}}, \"EndTime\": 1575995903.490539, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490521}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 82.81015852864583, \"sum\": 82.81015852864583, \"min\": 82.81015852864583}}, \"EndTime\": 1575995903.490599, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490581}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 151.14465872395834, \"sum\": 151.14465872395834, \"min\": 151.14465872395834}}, \"EndTime\": 1575995903.490646, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490636}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 77.0905814453125, \"sum\": 77.0905814453125, \"min\": 77.0905814453125}}, \"EndTime\": 1575995903.490701, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490684}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 134.15393658854165, \"sum\": 134.15393658854165, \"min\": 134.15393658854165}}, \"EndTime\": 1575995903.490751, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490739}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.373342460123698, \"sum\": 4.373342460123698, \"min\": 4.373342460123698}}, \"EndTime\": 1575995903.490789, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490775}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.1581230631510415, \"sum\": 7.1581230631510415, \"min\": 7.1581230631510415}}, \"EndTime\": 1575995903.490848, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490831}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.0708734903971355, \"sum\": 3.0708734903971355, \"min\": 3.0708734903971355}}, \"EndTime\": 1575995903.490897, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490882}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.942035017903645, \"sum\": 6.942035017903645, \"min\": 6.942035017903645}}, \"EndTime\": 1575995903.490953, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490937}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 198.6563369140625, \"sum\": 198.6563369140625, \"min\": 198.6563369140625}}, \"EndTime\": 1575995903.491009, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.490993}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 141.989955859375, \"sum\": 141.989955859375, \"min\": 141.989955859375}}, \"EndTime\": 1575995903.491059, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491048}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 81.71495677083334, \"sum\": 81.71495677083334, \"min\": 81.71495677083334}}, \"EndTime\": 1575995903.491089, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491081}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 103.23855826822917, \"sum\": 103.23855826822917, \"min\": 103.23855826822917}}, \"EndTime\": 1575995903.491138, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491124}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 12.74051298421224, \"sum\": 12.74051298421224, \"min\": 12.74051298421224}}, \"EndTime\": 1575995903.491183, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491168}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.588346354166666, \"sum\": 6.588346354166666, \"min\": 6.588346354166666}}, \"EndTime\": 1575995903.491237, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491222}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.774304890950521, \"sum\": 5.774304890950521, \"min\": 5.774304890950521}}, \"EndTime\": 1575995903.491292, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491276}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.437981363932292, \"sum\": 7.437981363932292, \"min\": 7.437981363932292}}, \"EndTime\": 1575995903.491348, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491332}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 121.5871546875, \"sum\": 121.5871546875, \"min\": 121.5871546875}}, \"EndTime\": 1575995903.491425, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491387}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 173.05330611979167, \"sum\": 173.05330611979167, \"min\": 173.05330611979167}}, \"EndTime\": 1575995903.491485, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491468}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 137.80516943359376, \"sum\": 137.80516943359376, \"min\": 137.80516943359376}}, \"EndTime\": 1575995903.491542, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491526}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 89.5692541015625, \"sum\": 89.5692541015625, \"min\": 89.5692541015625}}, \"EndTime\": 1575995903.491611, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491592}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.422241939290364, \"sum\": 4.422241939290364, \"min\": 4.422241939290364}}, \"EndTime\": 1575995903.491669, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491652}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.959726965332031, \"sum\": 8.959726965332031, \"min\": 8.959726965332031}}, \"EndTime\": 1575995903.491737, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491719}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.898608312988281, \"sum\": 5.898608312988281, \"min\": 5.898608312988281}}, \"EndTime\": 1575995903.491795, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491778}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 15.541463777669271, \"sum\": 15.541463777669271, \"min\": 15.541463777669271}}, \"EndTime\": 1575995903.491854, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491838}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 137.39989153645834, \"sum\": 137.39989153645834, \"min\": 137.39989153645834}}, \"EndTime\": 1575995903.491908, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491893}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 159.04851067708333, \"sum\": 159.04851067708333, \"min\": 159.04851067708333}}, \"EndTime\": 1575995903.491964, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491948}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 130.7709587890625, \"sum\": 130.7709587890625, \"min\": 130.7709587890625}}, \"EndTime\": 1575995903.492011, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.491996}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 141.09874895833335, \"sum\": 141.09874895833335, \"min\": 141.09874895833335}}, \"EndTime\": 1575995903.492058, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995903.492044}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:23 INFO 139764330137408] #quality_metric: host=algo-1, epoch=5, train binary_classification_hinge_loss_objective <loss>=6.2977058431\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:23 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=binary_classification_hinge_loss_objective, value=3.0708734904\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:23 INFO 139764330137408] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:23 INFO 139764330137408] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 198, \"sum\": 198.0, \"min\": 198}, \"Total Records Seen\": {\"count\": 1, \"max\": 192972, \"sum\": 192972.0, \"min\": 192972}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1575995903.494754, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1575995902.541347}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:23 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=31632.2025564 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:24.493] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 998, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.375029899088542, \"sum\": 4.375029899088542, \"min\": 4.375029899088542}}, \"EndTime\": 1575995904.494027, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.493962}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.6598599772135416, \"sum\": 3.6598599772135416, \"min\": 3.6598599772135416}}, \"EndTime\": 1575995904.494088, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494076}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.8212795654296876, \"sum\": 2.8212795654296876, \"min\": 2.8212795654296876}}, \"EndTime\": 1575995904.494121, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494112}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.7897705078125, \"sum\": 7.7897705078125, \"min\": 7.7897705078125}}, \"EndTime\": 1575995904.49417, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494157}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 43.6631466796875, \"sum\": 43.6631466796875, \"min\": 43.6631466796875}}, \"EndTime\": 1575995904.49422, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494206}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 144.69629270833335, \"sum\": 144.69629270833335, \"min\": 144.69629270833335}}, \"EndTime\": 1575995904.494272, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494256}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 192.43981243489583, \"sum\": 192.43981243489583, \"min\": 192.43981243489583}}, \"EndTime\": 1575995904.494328, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494312}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 59.56387115885417, \"sum\": 59.56387115885417, \"min\": 59.56387115885417}}, \"EndTime\": 1575995904.494387, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494371}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.668621166992187, \"sum\": 6.668621166992187, \"min\": 6.668621166992187}}, \"EndTime\": 1575995904.494424, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494411}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.078927099609375, \"sum\": 6.078927099609375, \"min\": 6.078927099609375}}, \"EndTime\": 1575995904.494478, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494462}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.048581170654297, \"sum\": 3.048581170654297, \"min\": 3.048581170654297}}, \"EndTime\": 1575995904.494534, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494518}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.468805769856771, \"sum\": 5.468805769856771, \"min\": 5.468805769856771}}, \"EndTime\": 1575995904.49457, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494558}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 126.55232174479167, \"sum\": 126.55232174479167, \"min\": 126.55232174479167}}, \"EndTime\": 1575995904.494622, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494607}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 246.943048828125, \"sum\": 246.943048828125, \"min\": 246.943048828125}}, \"EndTime\": 1575995904.494677, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494662}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 51.84606744791667, \"sum\": 51.84606744791667, \"min\": 51.84606744791667}}, \"EndTime\": 1575995904.494732, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494717}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 139.66278984375, \"sum\": 139.66278984375, \"min\": 139.66278984375}}, \"EndTime\": 1575995904.494788, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494772}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.020865535481772, \"sum\": 10.020865535481772, \"min\": 10.020865535481772}}, \"EndTime\": 1575995904.494846, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494828}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 13.136404524739584, \"sum\": 13.136404524739584, \"min\": 13.136404524739584}}, \"EndTime\": 1575995904.494904, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494888}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 13.567036572265625, \"sum\": 13.567036572265625, \"min\": 13.567036572265625}}, \"EndTime\": 1575995904.494962, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.494945}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 9.188894278971354, \"sum\": 9.188894278971354, \"min\": 9.188894278971354}}, \"EndTime\": 1575995904.495019, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495003}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 252.25854420572918, \"sum\": 252.25854420572918, \"min\": 252.25854420572918}}, \"EndTime\": 1575995904.495077, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495061}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 111.62566061197917, \"sum\": 111.62566061197917, \"min\": 111.62566061197917}}, \"EndTime\": 1575995904.495133, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495118}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 145.0779533203125, \"sum\": 145.0779533203125, \"min\": 145.0779533203125}}, \"EndTime\": 1575995904.495165, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495157}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 211.79404557291667, \"sum\": 211.79404557291667, \"min\": 211.79404557291667}}, \"EndTime\": 1575995904.495206, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495193}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.245636275227865, \"sum\": 6.245636275227865, \"min\": 6.245636275227865}}, \"EndTime\": 1575995904.495259, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495245}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.800333544921875, \"sum\": 8.800333544921875, \"min\": 8.800333544921875}}, \"EndTime\": 1575995904.495302, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495288}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.852496545410156, \"sum\": 3.852496545410156, \"min\": 3.852496545410156}}, \"EndTime\": 1575995904.495356, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.49534}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.06526435546875, \"sum\": 10.06526435546875, \"min\": 10.06526435546875}}, \"EndTime\": 1575995904.495435, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495416}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 67.45370123697917, \"sum\": 67.45370123697917, \"min\": 67.45370123697917}}, \"EndTime\": 1575995904.495493, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495476}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 155.47190104166665, \"sum\": 155.47190104166665, \"min\": 155.47190104166665}}, \"EndTime\": 1575995904.495546, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.49553}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 191.123384765625, \"sum\": 191.123384765625, \"min\": 191.123384765625}}, \"EndTime\": 1575995904.495595, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.49558}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 229.81915065104167, \"sum\": 229.81915065104167, \"min\": 229.81915065104167}}, \"EndTime\": 1575995904.49564, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995904.495627}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:24 INFO 139764330137408] #quality_metric: host=algo-1, epoch=6, train binary_classification_hinge_loss_objective <loss>=4.37502989909\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:24 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=binary_classification_hinge_loss_objective, value=2.82127956543\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:24 INFO 139764330137408] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:24 INFO 139764330137408] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 229, \"sum\": 229.0, \"min\": 229}, \"Total Records Seen\": {\"count\": 1, \"max\": 223134, \"sum\": 223134.0, \"min\": 223134}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1575995904.498266, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1575995903.495348}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:24 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=30070.6760826 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:25.420] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 921, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.2542316935221356, \"sum\": 3.2542316935221356, \"min\": 3.2542316935221356}}, \"EndTime\": 1575995905.421095, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.420985}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.357687483723959, \"sum\": 8.357687483723959, \"min\": 8.357687483723959}}, \"EndTime\": 1575995905.421193, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421171}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.9786687154134115, \"sum\": 2.9786687154134115, \"min\": 2.9786687154134115}}, \"EndTime\": 1575995905.421259, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.42124}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.789256579589844, \"sum\": 4.789256579589844, \"min\": 4.789256579589844}}, \"EndTime\": 1575995905.421323, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421304}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 45.012538997395836, \"sum\": 45.012538997395836, \"min\": 45.012538997395836}}, \"EndTime\": 1575995905.421383, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421365}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 135.42146705729166, \"sum\": 135.42146705729166, \"min\": 135.42146705729166}}, \"EndTime\": 1575995905.421446, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421428}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 151.25772766927082, \"sum\": 151.25772766927082, \"min\": 151.25772766927082}}, \"EndTime\": 1575995905.421505, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421489}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 61.12243958333333, \"sum\": 61.12243958333333, \"min\": 61.12243958333333}}, \"EndTime\": 1575995905.421565, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421547}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.3027923217773436, \"sum\": 2.3027923217773436, \"min\": 2.3027923217773436}}, \"EndTime\": 1575995905.421626, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421609}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.5604411458333334, \"sum\": 2.5604411458333334, \"min\": 2.5604411458333334}}, \"EndTime\": 1575995905.421684, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421668}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.661304585774739, \"sum\": 4.661304585774739, \"min\": 4.661304585774739}}, \"EndTime\": 1575995905.421743, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421726}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.6161984293619795, \"sum\": 5.6161984293619795, \"min\": 5.6161984293619795}}, \"EndTime\": 1575995905.421802, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421784}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 103.57127786458334, \"sum\": 103.57127786458334, \"min\": 103.57127786458334}}, \"EndTime\": 1575995905.42186, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421844}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 83.27187897135417, \"sum\": 83.27187897135417, \"min\": 83.27187897135417}}, \"EndTime\": 1575995905.421918, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421902}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 82.67572444661458, \"sum\": 82.67572444661458, \"min\": 82.67572444661458}}, \"EndTime\": 1575995905.421976, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.421959}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 107.3560388671875, \"sum\": 107.3560388671875, \"min\": 107.3560388671875}}, \"EndTime\": 1575995905.422034, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422018}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.644666662597656, \"sum\": 5.644666662597656, \"min\": 5.644666662597656}}, \"EndTime\": 1575995905.42209, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422075}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.9900361287434896, \"sum\": 3.9900361287434896, \"min\": 3.9900361287434896}}, \"EndTime\": 1575995905.42215, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422133}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.617208455403646, \"sum\": 5.617208455403646, \"min\": 5.617208455403646}}, \"EndTime\": 1575995905.422207, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422191}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.745695243326823, \"sum\": 5.745695243326823, \"min\": 5.745695243326823}}, \"EndTime\": 1575995905.422264, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422248}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 151.88879293619792, \"sum\": 151.88879293619792, \"min\": 151.88879293619792}}, \"EndTime\": 1575995905.422322, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422305}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 81.82287428385416, \"sum\": 81.82287428385416, \"min\": 81.82287428385416}}, \"EndTime\": 1575995905.422378, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422363}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 138.99669557291668, \"sum\": 138.99669557291668, \"min\": 138.99669557291668}}, \"EndTime\": 1575995905.422435, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.42242}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 227.746209375, \"sum\": 227.746209375, \"min\": 227.746209375}}, \"EndTime\": 1575995905.422494, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422478}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.86231797281901, \"sum\": 4.86231797281901, \"min\": 4.86231797281901}}, \"EndTime\": 1575995905.422551, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422535}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.495894124348958, \"sum\": 8.495894124348958, \"min\": 8.495894124348958}}, \"EndTime\": 1575995905.422607, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422591}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.263806705729166, \"sum\": 7.263806705729166, \"min\": 7.263806705729166}}, \"EndTime\": 1575995905.422666, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422649}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 13.756199479166666, \"sum\": 13.756199479166666, \"min\": 13.756199479166666}}, \"EndTime\": 1575995905.422724, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422708}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 133.716979296875, \"sum\": 133.716979296875, \"min\": 133.716979296875}}, \"EndTime\": 1575995905.422782, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422765}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 157.27286979166666, \"sum\": 157.27286979166666, \"min\": 157.27286979166666}}, \"EndTime\": 1575995905.422842, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422824}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 114.23751666666666, \"sum\": 114.23751666666666, \"min\": 114.23751666666666}}, \"EndTime\": 1575995905.4229, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422884}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 187.98846770833333, \"sum\": 187.98846770833333, \"min\": 187.98846770833333}}, \"EndTime\": 1575995905.422961, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995905.422943}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:25 INFO 139764330137408] #quality_metric: host=algo-1, epoch=7, train binary_classification_hinge_loss_objective <loss>=3.25423169352\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:25 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=binary_classification_hinge_loss_objective, value=2.30279232178\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:25 INFO 139764330137408] Epoch 7: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:25 INFO 139764330137408] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 260, \"sum\": 260.0, \"min\": 260}, \"Total Records Seen\": {\"count\": 1, \"max\": 253296, \"sum\": 253296.0, \"min\": 253296}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1575995905.426947, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1575995904.498881}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:25 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=32495.9279456 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:26.442] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 1014, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.5364619120279945, \"sum\": 5.5364619120279945, \"min\": 5.5364619120279945}}, \"EndTime\": 1575995906.44243, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.442337}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.613866951497396, \"sum\": 7.613866951497396, \"min\": 7.613866951497396}}, \"EndTime\": 1575995906.442522, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.442502}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.896480598958333, \"sum\": 6.896480598958333, \"min\": 6.896480598958333}}, \"EndTime\": 1575995906.442598, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.442578}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.7345646240234376, \"sum\": 3.7345646240234376, \"min\": 3.7345646240234376}}, \"EndTime\": 1575995906.442656, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.442642}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 47.0160677734375, \"sum\": 47.0160677734375, \"min\": 47.0160677734375}}, \"EndTime\": 1575995906.442707, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.442696}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 140.81591640625, \"sum\": 140.81591640625, \"min\": 140.81591640625}}, \"EndTime\": 1575995906.442761, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.442745}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 110.9809703125, \"sum\": 110.9809703125, \"min\": 110.9809703125}}, \"EndTime\": 1575995906.442815, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.4428}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 75.80893271484375, \"sum\": 75.80893271484375, \"min\": 75.80893271484375}}, \"EndTime\": 1575995906.44287, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.442856}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.713458125813802, \"sum\": 3.713458125813802, \"min\": 3.713458125813802}}, \"EndTime\": 1575995906.442909, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.442895}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.1507659403483075, \"sum\": 4.1507659403483075, \"min\": 4.1507659403483075}}, \"EndTime\": 1575995906.442954, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.44294}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.514012915039062, \"sum\": 5.514012915039062, \"min\": 5.514012915039062}}, \"EndTime\": 1575995906.443003, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.442992}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.4906763753255206, \"sum\": 5.4906763753255206, \"min\": 5.4906763753255206}}, \"EndTime\": 1575995906.443057, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443042}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 50.28221282552083, \"sum\": 50.28221282552083, \"min\": 50.28221282552083}}, \"EndTime\": 1575995906.443106, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443092}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 291.36361692708334, \"sum\": 291.36361692708334, \"min\": 291.36361692708334}}, \"EndTime\": 1575995906.443161, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443146}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 151.69631171875, \"sum\": 151.69631171875, \"min\": 151.69631171875}}, \"EndTime\": 1575995906.443213, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443201}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 70.05976809895833, \"sum\": 70.05976809895833, \"min\": 70.05976809895833}}, \"EndTime\": 1575995906.443244, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443236}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.726371769205729, \"sum\": 4.726371769205729, \"min\": 4.726371769205729}}, \"EndTime\": 1575995906.443286, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443274}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.469318658447266, \"sum\": 6.469318658447266, \"min\": 6.469318658447266}}, \"EndTime\": 1575995906.443323, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443309}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.2789796142578127, \"sum\": 3.2789796142578127, \"min\": 3.2789796142578127}}, \"EndTime\": 1575995906.443376, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.44336}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.029426969401042, \"sum\": 4.029426969401042, \"min\": 4.029426969401042}}, \"EndTime\": 1575995906.443461, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443442}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 183.61231041666667, \"sum\": 183.61231041666667, \"min\": 183.61231041666667}}, \"EndTime\": 1575995906.443519, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443502}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 112.76660377604166, \"sum\": 112.76660377604166, \"min\": 112.76660377604166}}, \"EndTime\": 1575995906.443561, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443552}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 133.95556458333334, \"sum\": 133.95556458333334, \"min\": 133.95556458333334}}, \"EndTime\": 1575995906.443609, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443594}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 85.23238470052084, \"sum\": 85.23238470052084, \"min\": 85.23238470052084}}, \"EndTime\": 1575995906.443677, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443659}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.6619215291341147, \"sum\": 3.6619215291341147, \"min\": 3.6619215291341147}}, \"EndTime\": 1575995906.443742, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443725}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.410997644042969, \"sum\": 3.410997644042969, \"min\": 3.410997644042969}}, \"EndTime\": 1575995906.443803, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443786}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.855066646321614, \"sum\": 10.855066646321614, \"min\": 10.855066646321614}}, \"EndTime\": 1575995906.443854, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443839}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 10.06041454671224, \"sum\": 10.06041454671224, \"min\": 10.06041454671224}}, \"EndTime\": 1575995906.443913, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443897}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 137.29898684895832, \"sum\": 137.29898684895832, \"min\": 137.29898684895832}}, \"EndTime\": 1575995906.443968, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.443952}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 172.73219290364582, \"sum\": 172.73219290364582, \"min\": 172.73219290364582}}, \"EndTime\": 1575995906.444019, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.444004}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 276.4004068359375, \"sum\": 276.4004068359375, \"min\": 276.4004068359375}}, \"EndTime\": 1575995906.444062, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.444048}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 201.24813619791666, \"sum\": 201.24813619791666, \"min\": 201.24813619791666}}, \"EndTime\": 1575995906.44412, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995906.444103}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:26 INFO 139764330137408] #quality_metric: host=algo-1, epoch=8, train binary_classification_hinge_loss_objective <loss>=5.53646191203\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:26 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=binary_classification_hinge_loss_objective, value=3.27897961426\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:26 INFO 139764330137408] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 291, \"sum\": 291.0, \"min\": 291}, \"Total Records Seen\": {\"count\": 1, \"max\": 283458, \"sum\": 283458.0, \"min\": 283458}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1575995906.446355, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1575995905.427592}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:26 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=29602.8612551 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:27.543] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 1095, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.865129433186849, \"sum\": 2.865129433186849, \"min\": 2.865129433186849}}, \"EndTime\": 1575995907.543196, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543093}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.579080314127604, \"sum\": 5.579080314127604, \"min\": 5.579080314127604}}, \"EndTime\": 1575995907.543283, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543265}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.679639217122396, \"sum\": 3.679639217122396, \"min\": 3.679639217122396}}, \"EndTime\": 1575995907.543349, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.54333}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.013358799235026, \"sum\": 3.013358799235026, \"min\": 3.013358799235026}}, \"EndTime\": 1575995907.543434, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543415}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 123.10263059895833, \"sum\": 123.10263059895833, \"min\": 123.10263059895833}}, \"EndTime\": 1575995907.543498, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.54348}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 126.00049661458333, \"sum\": 126.00049661458333, \"min\": 126.00049661458333}}, \"EndTime\": 1575995907.543559, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543542}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 82.09430559895833, \"sum\": 82.09430559895833, \"min\": 82.09430559895833}}, \"EndTime\": 1575995907.543624, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543608}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 56.5398986328125, \"sum\": 56.5398986328125, \"min\": 56.5398986328125}}, \"EndTime\": 1575995907.543684, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543669}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.8149481689453126, \"sum\": 2.8149481689453126, \"min\": 2.8149481689453126}}, \"EndTime\": 1575995907.543745, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543727}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.6943191569010416, \"sum\": 3.6943191569010416, \"min\": 3.6943191569010416}}, \"EndTime\": 1575995907.543805, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543788}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.612771630859375, \"sum\": 2.612771630859375, \"min\": 2.612771630859375}}, \"EndTime\": 1575995907.543865, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543848}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.033810217285156, \"sum\": 4.033810217285156, \"min\": 4.033810217285156}}, \"EndTime\": 1575995907.543923, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543906}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 45.070558984375, \"sum\": 45.070558984375, \"min\": 45.070558984375}}, \"EndTime\": 1575995907.543979, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.543963}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 137.90989427083332, \"sum\": 137.90989427083332, \"min\": 137.90989427083332}}, \"EndTime\": 1575995907.544039, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544022}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 130.93988463541666, \"sum\": 130.93988463541666, \"min\": 130.93988463541666}}, \"EndTime\": 1575995907.544099, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544082}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 64.18531256510417, \"sum\": 64.18531256510417, \"min\": 64.18531256510417}}, \"EndTime\": 1575995907.544154, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544138}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.654799454752604, \"sum\": 5.654799454752604, \"min\": 5.654799454752604}}, \"EndTime\": 1575995907.544211, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544194}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.87098154703776, \"sum\": 6.87098154703776, \"min\": 6.87098154703776}}, \"EndTime\": 1575995907.54428, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544261}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.8772082885742187, \"sum\": 2.8772082885742187, \"min\": 2.8772082885742187}}, \"EndTime\": 1575995907.544342, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544325}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.519998596191407, \"sum\": 5.519998596191407, \"min\": 5.519998596191407}}, \"EndTime\": 1575995907.544402, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544385}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 127.0099099609375, \"sum\": 127.0099099609375, \"min\": 127.0099099609375}}, \"EndTime\": 1575995907.54446, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544443}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 209.81309075520832, \"sum\": 209.81309075520832, \"min\": 209.81309075520832}}, \"EndTime\": 1575995907.544527, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544509}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 114.40720390625, \"sum\": 114.40720390625, \"min\": 114.40720390625}}, \"EndTime\": 1575995907.544596, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544578}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 180.241318359375, \"sum\": 180.241318359375, \"min\": 180.241318359375}}, \"EndTime\": 1575995907.544664, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544645}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.1505685465494793, \"sum\": 3.1505685465494793, \"min\": 3.1505685465494793}}, \"EndTime\": 1575995907.544733, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544715}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.629088509114584, \"sum\": 6.629088509114584, \"min\": 6.629088509114584}}, \"EndTime\": 1575995907.5448, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544783}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.8963490600585935, \"sum\": 5.8963490600585935, \"min\": 5.8963490600585935}}, \"EndTime\": 1575995907.544859, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544842}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.227815380859376, \"sum\": 8.227815380859376, \"min\": 8.227815380859376}}, \"EndTime\": 1575995907.544927, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544909}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 100.93519947916667, \"sum\": 100.93519947916667, \"min\": 100.93519947916667}}, \"EndTime\": 1575995907.544995, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.544976}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 124.77576927083334, \"sum\": 124.77576927083334, \"min\": 124.77576927083334}}, \"EndTime\": 1575995907.545065, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.545045}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 102.770119921875, \"sum\": 102.770119921875, \"min\": 102.770119921875}}, \"EndTime\": 1575995907.545133, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.545114}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 111.14908606770834, \"sum\": 111.14908606770834, \"min\": 111.14908606770834}}, \"EndTime\": 1575995907.545196, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995907.545179}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:27 INFO 139764330137408] #quality_metric: host=algo-1, epoch=9, train binary_classification_hinge_loss_objective <loss>=2.86512943319\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:27 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=binary_classification_hinge_loss_objective, value=2.61277163086\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:27 INFO 139764330137408] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 322, \"sum\": 322.0, \"min\": 322}, \"Total Records Seen\": {\"count\": 1, \"max\": 313620, \"sum\": 313620.0, \"min\": 313620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1575995907.547273, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1575995906.446964}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:27 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=27409.8612133 records/second\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:28.631] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 1083, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.820531028238932, \"sum\": 4.820531028238932, \"min\": 4.820531028238932}}, \"EndTime\": 1575995908.631456, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631336}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.367692195638021, \"sum\": 2.367692195638021, \"min\": 2.367692195638021}}, \"EndTime\": 1575995908.63153, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631512}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.864942451985677, \"sum\": 3.864942451985677, \"min\": 3.864942451985677}}, \"EndTime\": 1575995908.631584, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631569}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.782286932373047, \"sum\": 3.782286932373047, \"min\": 3.782286932373047}}, \"EndTime\": 1575995908.631637, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631621}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 117.96703854166667, \"sum\": 117.96703854166667, \"min\": 117.96703854166667}}, \"EndTime\": 1575995908.631693, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631677}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 144.50183932291668, \"sum\": 144.50183932291668, \"min\": 144.50183932291668}}, \"EndTime\": 1575995908.631751, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631735}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 38.950119140625, \"sum\": 38.950119140625, \"min\": 38.950119140625}}, \"EndTime\": 1575995908.631813, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631796}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 89.96924615885416, \"sum\": 89.96924615885416, \"min\": 89.96924615885416}}, \"EndTime\": 1575995908.631874, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631858}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.919651192220052, \"sum\": 4.919651192220052, \"min\": 4.919651192220052}}, \"EndTime\": 1575995908.631932, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631916}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 11.49011025390625, \"sum\": 11.49011025390625, \"min\": 11.49011025390625}}, \"EndTime\": 1575995908.631989, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.631973}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.916177921549479, \"sum\": 6.916177921549479, \"min\": 6.916177921549479}}, \"EndTime\": 1575995908.632045, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632029}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.996851123046875, \"sum\": 3.996851123046875, \"min\": 3.996851123046875}}, \"EndTime\": 1575995908.632103, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632087}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 95.52050771484375, \"sum\": 95.52050771484375, \"min\": 95.52050771484375}}, \"EndTime\": 1575995908.632161, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632145}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 52.517932421875, \"sum\": 52.517932421875, \"min\": 52.517932421875}}, \"EndTime\": 1575995908.63222, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632203}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 108.14068307291667, \"sum\": 108.14068307291667, \"min\": 108.14068307291667}}, \"EndTime\": 1575995908.632277, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632261}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 96.75595026041667, \"sum\": 96.75595026041667, \"min\": 96.75595026041667}}, \"EndTime\": 1575995908.632345, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632327}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.790551053873698, \"sum\": 4.790551053873698, \"min\": 4.790551053873698}}, \"EndTime\": 1575995908.632404, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632387}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.200770751953126, \"sum\": 8.200770751953126, \"min\": 8.200770751953126}}, \"EndTime\": 1575995908.632461, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632444}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.6188241068522133, \"sum\": 2.6188241068522133, \"min\": 2.6188241068522133}}, \"EndTime\": 1575995908.632519, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632503}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.101066943359375, \"sum\": 4.101066943359375, \"min\": 4.101066943359375}}, \"EndTime\": 1575995908.632583, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632566}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 96.42890397135416, \"sum\": 96.42890397135416, \"min\": 96.42890397135416}}, \"EndTime\": 1575995908.632641, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632624}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 121.43089166666667, \"sum\": 121.43089166666667, \"min\": 121.43089166666667}}, \"EndTime\": 1575995908.632702, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632684}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 105.00002819010416, \"sum\": 105.00002819010416, \"min\": 105.00002819010416}}, \"EndTime\": 1575995908.632762, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632744}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 201.5205115234375, \"sum\": 201.5205115234375, \"min\": 201.5205115234375}}, \"EndTime\": 1575995908.63282, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632803}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.3185729451497394, \"sum\": 3.3185729451497394, \"min\": 3.3185729451497394}}, \"EndTime\": 1575995908.632882, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632865}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 8.874375081380208, \"sum\": 8.874375081380208, \"min\": 8.874375081380208}}, \"EndTime\": 1575995908.632939, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632923}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 11.221251635742188, \"sum\": 11.221251635742188, \"min\": 11.221251635742188}}, \"EndTime\": 1575995908.632986, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.632971}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 6.412202270507812, \"sum\": 6.412202270507812, \"min\": 6.412202270507812}}, \"EndTime\": 1575995908.633051, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.633034}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 189.179584765625, \"sum\": 189.179584765625, \"min\": 189.179584765625}}, \"EndTime\": 1575995908.633104, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.633092}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 144.09962604166665, \"sum\": 144.09962604166665, \"min\": 144.09962604166665}}, \"EndTime\": 1575995908.633155, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.633139}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 85.89905735677084, \"sum\": 85.89905735677084, \"min\": 85.89905735677084}}, \"EndTime\": 1575995908.633224, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.633205}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 104.18714016927083, \"sum\": 104.18714016927083, \"min\": 104.18714016927083}}, \"EndTime\": 1575995908.633293, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995908.633275}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:28 INFO 139764330137408] #quality_metric: host=algo-1, epoch=10, train binary_classification_hinge_loss_objective <loss>=4.82053102824\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:28 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=binary_classification_hinge_loss_objective, value=2.36769219564\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:28 INFO 139764330137408] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 353, \"sum\": 353.0, \"min\": 353}, \"Total Records Seen\": {\"count\": 1, \"max\": 343782, \"sum\": 343782.0, \"min\": 343782}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1575995908.635432, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1575995907.547876}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:28 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=27730.762296 records/second\u001b[0m\n",
      "\n",
      "2019-12-10 16:38:41 Uploading - Uploading generated training model\n",
      "2019-12-10 16:38:41 Completed - Training job completed\n",
      "\u001b[34m[2019-12-10 16:38:29.521] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 25, \"duration\": 885, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.251494755045573, \"sum\": 3.251494755045573, \"min\": 3.251494755045573}}, \"EndTime\": 1575995909.522095, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.521979}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.6692052978515624, \"sum\": 2.6692052978515624, \"min\": 2.6692052978515624}}, \"EndTime\": 1575995909.522202, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522179}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.601178499348959, \"sum\": 4.601178499348959, \"min\": 4.601178499348959}}, \"EndTime\": 1575995909.522271, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522252}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.56103671875, \"sum\": 5.56103671875, \"min\": 5.56103671875}}, \"EndTime\": 1575995909.522336, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522318}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 73.45474055989584, \"sum\": 73.45474055989584, \"min\": 73.45474055989584}}, \"EndTime\": 1575995909.522407, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522388}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 71.1409806640625, \"sum\": 71.1409806640625, \"min\": 71.1409806640625}}, \"EndTime\": 1575995909.52247, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522453}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 46.602880078125, \"sum\": 46.602880078125, \"min\": 46.602880078125}}, \"EndTime\": 1575995909.522531, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522513}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 108.47040494791666, \"sum\": 108.47040494791666, \"min\": 108.47040494791666}}, \"EndTime\": 1575995909.522591, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522574}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.6804083984375, \"sum\": 3.6804083984375, \"min\": 3.6804083984375}}, \"EndTime\": 1575995909.522651, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522635}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.9839328857421874, \"sum\": 2.9839328857421874, \"min\": 2.9839328857421874}}, \"EndTime\": 1575995909.52271, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522693}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.502864129638672, \"sum\": 2.502864129638672, \"min\": 2.502864129638672}}, \"EndTime\": 1575995909.522771, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522753}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.7457130574544273, \"sum\": 3.7457130574544273, \"min\": 3.7457130574544273}}, \"EndTime\": 1575995909.52283, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522813}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 107.443551171875, \"sum\": 107.443551171875, \"min\": 107.443551171875}}, \"EndTime\": 1575995909.522888, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522871}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 103.5107435546875, \"sum\": 103.5107435546875, \"min\": 103.5107435546875}}, \"EndTime\": 1575995909.522947, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.52293}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 91.19570436197917, \"sum\": 91.19570436197917, \"min\": 91.19570436197917}}, \"EndTime\": 1575995909.523006, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.522989}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 73.98517740885417, \"sum\": 73.98517740885417, \"min\": 73.98517740885417}}, \"EndTime\": 1575995909.523066, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523048}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 2.539227014160156, \"sum\": 2.539227014160156, \"min\": 2.539227014160156}}, \"EndTime\": 1575995909.523151, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523132}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.590322094726562, \"sum\": 5.590322094726562, \"min\": 5.590322094726562}}, \"EndTime\": 1575995909.523213, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523194}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 3.2178380249023437, \"sum\": 3.2178380249023437, \"min\": 3.2178380249023437}}, \"EndTime\": 1575995909.523272, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523254}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 5.651786946614584, \"sum\": 5.651786946614584, \"min\": 5.651786946614584}}, \"EndTime\": 1575995909.523333, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523315}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 91.10094850260417, \"sum\": 91.10094850260417, \"min\": 91.10094850260417}}, \"EndTime\": 1575995909.523414, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523374}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 101.29894752604167, \"sum\": 101.29894752604167, \"min\": 101.29894752604167}}, \"EndTime\": 1575995909.523481, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523462}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 86.04729928385417, \"sum\": 86.04729928385417, \"min\": 86.04729928385417}}, \"EndTime\": 1575995909.523541, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523524}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 240.17409010416668, \"sum\": 240.17409010416668, \"min\": 240.17409010416668}}, \"EndTime\": 1575995909.523599, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523582}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.337537947591146, \"sum\": 4.337537947591146, \"min\": 4.337537947591146}}, \"EndTime\": 1575995909.52366, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523641}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 7.42775673828125, \"sum\": 7.42775673828125, \"min\": 7.42775673828125}}, \"EndTime\": 1575995909.52372, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523702}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.294955065917969, \"sum\": 4.294955065917969, \"min\": 4.294955065917969}}, \"EndTime\": 1575995909.523779, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523761}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 4.794263399251302, \"sum\": 4.794263399251302, \"min\": 4.794263399251302}}, \"EndTime\": 1575995909.523839, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.52382}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 139.545578515625, \"sum\": 139.545578515625, \"min\": 139.545578515625}}, \"EndTime\": 1575995909.523898, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523881}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 54.55650286458334, \"sum\": 54.55650286458334, \"min\": 54.55650286458334}}, \"EndTime\": 1575995909.523957, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523939}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 75.47596484375, \"sum\": 75.47596484375, \"min\": 75.47596484375}}, \"EndTime\": 1575995909.524017, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.523999}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_hinge_loss_objective\": {\"count\": 1, \"max\": 121.98784921875, \"sum\": 121.98784921875, \"min\": 121.98784921875}}, \"EndTime\": 1575995909.524075, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995909.524058}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #quality_metric: host=algo-1, epoch=11, train binary_classification_hinge_loss_objective <loss>=3.25149475505\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #early_stopping_criteria_metric: host=algo-1, epoch=11, criteria=binary_classification_hinge_loss_objective, value=2.50286412964\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Total Batches Seen\": {\"count\": 1, \"max\": 384, \"sum\": 384.0, \"min\": 384}, \"Total Records Seen\": {\"count\": 1, \"max\": 373944, \"sum\": 373944.0, \"min\": 373944}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 30162, \"sum\": 30162.0, \"min\": 30162}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1575995909.526294, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1575995908.636046}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #throughput_metric: host=algo-1, train throughput=33875.8357586 records/second\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 WARNING 139764330137408] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 WARNING 139764330137408] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:29.532] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 27, \"duration\": 5, \"num_examples\": 1, \"num_bytes\": 300000}\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:29.736] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 200, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m[2019-12-10 16:38:29.866] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 102, \"num_examples\": 31, \"num_bytes\": 9048600}\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #train_score (algo-1) : ('binary_classification_hinge_loss_objective', 3.4023055215783335)\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #train_score (algo-1) : ('binary_classification_accuracy', 0.7899675087858895)\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #train_score (algo-1) : ('binary_f_1.000', 0.3690867443481725)\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #train_score (algo-1) : ('precision', 0.7315436241610739)\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #train_score (algo-1) : ('recall', 0.24680340969632392)\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #quality_metric: host=algo-1, train binary_classification_hinge_loss_objective <loss>=3.40230552158\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.789967508786\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.369086744348\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #quality_metric: host=algo-1, train precision <score>=0.731543624161\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] #quality_metric: host=algo-1, train recall <score>=0.246803409696\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] Best model found for hyperparameters: {\"lr_scheduler_step\": 10, \"wd\": 0.01, \"optimizer\": \"adam\", \"lr_scheduler_factor\": 0.99, \"l1\": 0.0, \"learning_rate\": 0.005, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] Saved checkpoint to \"/tmp/tmpXaRhnP/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/10/2019 16:38:29 INFO 139764330137408] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 12786.642074584961, \"sum\": 12786.642074584961, \"min\": 12786.642074584961}, \"finalize.time\": {\"count\": 1, \"max\": 340.8169746398926, \"sum\": 340.8169746398926, \"min\": 340.8169746398926}, \"initialize.time\": {\"count\": 1, \"max\": 209.5959186553955, \"sum\": 209.5959186553955, \"min\": 209.5959186553955}, \"check_early_stopping.time\": {\"count\": 12, \"max\": 1.0859966278076172, \"sum\": 7.542133331298828, \"min\": 0.1900196075439453}, \"setuptime\": {\"count\": 1, \"max\": 25.17104148864746, \"sum\": 25.17104148864746, \"min\": 25.17104148864746}, \"update.time\": {\"count\": 12, \"max\": 1214.669942855835, \"sum\": 12126.73282623291, \"min\": 890.031099319458}, \"epochs\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1575995909.878919, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1575995897.175279}\n",
      "\u001b[0m\n",
      "Training seconds: 69\n",
      "Billable seconds: 69\n",
      "-------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "linear.fit({'train': s3_train_data})\n",
    "linear_predictor = linear.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "linear_predictor.content_type = 'text/csv'\n",
    "linear_predictor.serializer = csv_serializer\n",
    "linear_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Small test to check the code\n",
    "# result = linear_predictor.predict(model_data[0])\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "scores=[]\n",
    "\n",
    "for array in model_data:\n",
    "    result = linear_predictor.predict(array)\n",
    "#     print(result)\n",
    "    predictions += [r['predicted_label'] for r in result['predictions']]\n",
    "    scores += [r['score'] for r in result['predictions']]\n",
    "#     print(predicted_label)\n",
    "predictions = np.array(predictions)\n",
    "# Push into our pandas dataframe\n",
    "# data['Predicted'] = predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morethan_list=[]\n",
    "# lessthan_list=[]\n",
    "# for i in range(0,len(scores)):\n",
    "#     if predictions[i]==0:\n",
    "#         lessthan_list.append(scores[i])\n",
    "#     else:\n",
    "#         morethan_list.append(scores[i])\n",
    "# max(lessthan_list)\n",
    "# min(morethan_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing test labels\n",
    "### Developing labels: '0' = <=50K, '1' = >50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=test_label[0]\n",
    "labels=[]\n",
    "for i in test_label:\n",
    "    if i ==temp:\n",
    "        labels.append(0)#<=50K\n",
    "    else:\n",
    "        labels.append(1)\n",
    "labels=np.array(labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=0\n",
    "for i in range(0, labels.shape[0]):\n",
    "    if labels[i]==predictions[i]:\n",
    "        correct=correct+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11876"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct#Number of correct labels predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of correct predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885790172642763"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.021438121795654297,\n",
       " 0.05326090753078461,\n",
       " 6.050603133189725e-06,\n",
       " 0.0008763669757172465,\n",
       " 0.038076288998126984,\n",
       " 0.7235231995582581,\n",
       " 3.1665356448051796e-10,\n",
       " 0.13206003606319427,\n",
       " 0.9999964237213135,\n",
       " 0.9997689127922058,\n",
       " 0.9242222309112549,\n",
       " 0.10236988961696625,\n",
       " 2.713660933295614e-06,\n",
       " 0.00039460044354200363,\n",
       " 9.376765319757396e-07,\n",
       " 7.23431554661147e-08,\n",
       " 2.468503907948616e-06,\n",
       " 0.0006980500766076148,\n",
       " 0.03615233674645424,\n",
       " 0.9994522929191589,\n",
       " 4.238630992858816e-07,\n",
       " 1.2619689186976757e-06,\n",
       " 0.47122231125831604,\n",
       " 0.00012470853107515723,\n",
       " 0.9886903166770935,\n",
       " 3.576686538053764e-07,\n",
       " 0.14343968033790588,\n",
       " 0.018028369173407555,\n",
       " 0.0005860200617462397,\n",
       " 3.657900379039347e-06,\n",
       " 0.9900798797607422,\n",
       " 0.00011033770715584978,\n",
       " 1.5719297152827494e-06,\n",
       " 8.214288754970767e-06,\n",
       " 1.865900799202791e-06,\n",
       " 3.3775831980165094e-06,\n",
       " 0.6101195812225342,\n",
       " 0.00011559217819012702,\n",
       " 0.8873129487037659,\n",
       " 0.34352925419807434,\n",
       " 5.51465927856043e-06,\n",
       " 4.3556150330914534e-07,\n",
       " 0.9941415190696716,\n",
       " 0.011557157151401043,\n",
       " 0.010836180299520493,\n",
       " 0.03283701837062836,\n",
       " 0.0003755420621018857,\n",
       " 3.8676185795338824e-05,\n",
       " 0.9999958276748657,\n",
       " 0.8721637725830078,\n",
       " 0.007899289950728416,\n",
       " 0.08684541285037994,\n",
       " 7.669381375308149e-06,\n",
       " 0.0018204828957095742,\n",
       " 0.006129084154963493,\n",
       " 0.17209085822105408,\n",
       " 0.6771021485328674,\n",
       " 0.006723479367792606,\n",
       " 0.991454005241394,\n",
       " 0.00021644991647917777,\n",
       " 0.0010546984849497676,\n",
       " 5.278684511722531e-07,\n",
       " 0.003979167435318232,\n",
       " 0.794221043586731,\n",
       " 7.364303655776894e-07,\n",
       " 0.00028252441552467644,\n",
       " 0.9208986759185791,\n",
       " 2.15007253245858e-06,\n",
       " 0.17435865104198456,\n",
       " 3.749193240309978e-07,\n",
       " 0.020697711035609245,\n",
       " 3.160531836243763e-10,\n",
       " 5.269691314424563e-07,\n",
       " 6.421582270377257e-07,\n",
       " 0.8735059499740601,\n",
       " 0.00023735224385745823,\n",
       " 0.39477410912513733,\n",
       " 0.999695897102356,\n",
       " 0.00010314814426237717,\n",
       " 0.09050317108631134,\n",
       " 0.9300315380096436,\n",
       " 2.3272653137951238e-08,\n",
       " 0.8751532435417175,\n",
       " 0.8860642910003662,\n",
       " 1.2960620551893953e-05,\n",
       " 1.4554878191574971e-08,\n",
       " 0.5529801249504089,\n",
       " 1.5330142559832893e-05,\n",
       " 0.9999998807907104,\n",
       " 0.053936708718538284,\n",
       " 0.00102671526838094,\n",
       " 2.008182491408661e-06,\n",
       " 0.999864935874939,\n",
       " 1.0,\n",
       " 0.04704064503312111,\n",
       " 7.96152619386703e-07,\n",
       " 1.0302014743501786e-06,\n",
       " 0.9918505549430847,\n",
       " 2.4362432782254473e-07,\n",
       " 2.988376763823908e-07,\n",
       " 0.001230138004757464,\n",
       " 0.005195481237024069,\n",
       " 0.8667351007461548,\n",
       " 0.9970793724060059,\n",
       " 0.03717264160513878,\n",
       " 4.741087309412251e-07,\n",
       " 0.0007217701058834791,\n",
       " 0.946256697177887,\n",
       " 0.0931791365146637,\n",
       " 0.9145432710647583,\n",
       " 3.0734500455764646e-07,\n",
       " 1.5834986299978482e-07,\n",
       " 0.983639657497406,\n",
       " 0.00043094801367260516,\n",
       " 0.7816856503486633,\n",
       " 1.9521475280726008e-07,\n",
       " 0.8665512800216675,\n",
       " 1.2664087989833206e-05,\n",
       " 0.00709636090323329,\n",
       " 0.00024831650080159307,\n",
       " 0.00017354480223730206,\n",
       " 1.3114494322508108e-05,\n",
       " 0.07667785882949829,\n",
       " 0.8979224562644958,\n",
       " 6.159630720503628e-05,\n",
       " 0.8840955495834351,\n",
       " 0.024343186989426613,\n",
       " 0.0001875037996796891,\n",
       " 3.9874493040770176e-08,\n",
       " 0.014691846445202827,\n",
       " 0.1378304809331894,\n",
       " 3.058443553527468e-06,\n",
       " 1.5551503906863218e-07,\n",
       " 0.15852820873260498,\n",
       " 0.05630360171198845,\n",
       " 1.2964031625983807e-08,\n",
       " 9.454991413804237e-06,\n",
       " 1.8290238656959446e-08,\n",
       " 0.9959751963615417,\n",
       " 8.318934305862058e-06,\n",
       " 4.879872221863479e-07,\n",
       " 0.00038629001937806606,\n",
       " 6.523565616589622e-07,\n",
       " 0.03793980926275253,\n",
       " 0.00012138356396462768,\n",
       " 0.21780766546726227,\n",
       " 5.265121944830753e-05,\n",
       " 0.011994188651442528,\n",
       " 8.931278472346094e-08,\n",
       " 0.007498221471905708,\n",
       " 1.1715071224216445e-07,\n",
       " 0.8752639889717102,\n",
       " 8.35448304314923e-07,\n",
       " 0.011090177111327648,\n",
       " 0.07989466935396194,\n",
       " 1.0361279195736373e-10,\n",
       " 0.00033846954465843737,\n",
       " 0.0008201415184885263,\n",
       " 0.0006456836708821356,\n",
       " 0.9959985017776489,\n",
       " 0.017342543229460716,\n",
       " 0.17243079841136932,\n",
       " 6.798448026756887e-08,\n",
       " 4.2403371480759233e-07,\n",
       " 7.039704087219434e-06,\n",
       " 1.152017703454078e-09,\n",
       " 0.9356551766395569,\n",
       " 0.021513475105166435,\n",
       " 5.675070042343577e-06,\n",
       " 0.00025084931985475123,\n",
       " 8.14194390841294e-06,\n",
       " 0.00434914929792285,\n",
       " 0.00036157798604108393,\n",
       " 0.000995161710307002,\n",
       " 0.43347275257110596,\n",
       " 0.6115115880966187,\n",
       " 9.64953912330202e-08,\n",
       " 0.0002895148063544184,\n",
       " 0.8468133807182312,\n",
       " 0.15574944019317627,\n",
       " 0.24370713531970978,\n",
       " 9.123215072293078e-09,\n",
       " 1.5545467249467038e-05,\n",
       " 0.9999998807907104,\n",
       " 0.9997738003730774,\n",
       " 1.7572118338193832e-07,\n",
       " 0.8094584345817566,\n",
       " 0.9967447519302368,\n",
       " 0.019736390560865402,\n",
       " 1.0696091834461185e-07,\n",
       " 7.354812758819662e-09,\n",
       " 0.995560884475708,\n",
       " 4.773915861733258e-05,\n",
       " 1.0,\n",
       " 2.985078850770151e-11,\n",
       " 0.0009836690733209252,\n",
       " 0.001976229250431061,\n",
       " 1.1325084869895363e-06,\n",
       " 0.028179693967103958,\n",
       " 0.00019899045582860708,\n",
       " 0.7696042060852051,\n",
       " 0.0028645857237279415,\n",
       " 0.8189671039581299,\n",
       " 0.9809345602989197,\n",
       " 7.787073030840475e-08,\n",
       " 0.0011893593473359942,\n",
       " 0.9840493202209473,\n",
       " 0.00022305536549538374,\n",
       " 2.7750883813126848e-09,\n",
       " 1.2510174940416618e-07,\n",
       " 0.6625543236732483,\n",
       " 0.0010901360074058175,\n",
       " 0.00015349096793215722,\n",
       " 0.0004328005888964981,\n",
       " 5.189971830077411e-07,\n",
       " 2.928502681243117e-06,\n",
       " 5.267761480354238e-07,\n",
       " 0.06848977506160736,\n",
       " 0.08415050059556961,\n",
       " 4.148437710682629e-06,\n",
       " 0.9520988464355469,\n",
       " 0.9986385703086853,\n",
       " 3.257902676523372e-07,\n",
       " 0.9168033003807068,\n",
       " 4.774856279254891e-06,\n",
       " 0.12697702646255493,\n",
       " 0.04291254281997681,\n",
       " 0.17778299748897552,\n",
       " 6.61528574141812e-08,\n",
       " 0.9999634027481079,\n",
       " 0.7725507616996765,\n",
       " 0.18671409785747528,\n",
       " 1.0508595238434282e-07,\n",
       " 3.7446338296831527e-07,\n",
       " 0.0001105356786865741,\n",
       " 0.000667165033519268,\n",
       " 1.4515898705269592e-08,\n",
       " 3.903231160506948e-08,\n",
       " 0.0011453785700723529,\n",
       " 6.213157917045464e-07,\n",
       " 0.0009781253756955266,\n",
       " 0.15943405032157898,\n",
       " 2.1561423479976582e-10,\n",
       " 0.993682861328125,\n",
       " 0.00012672095908783376,\n",
       " 0.9207022786140442,\n",
       " 0.23836730420589447,\n",
       " 0.0013428949750959873,\n",
       " 0.00019932695431634784,\n",
       " 0.20588184893131256,\n",
       " 4.96137686489817e-10,\n",
       " 0.9999969005584717,\n",
       " 0.0035324017517268658,\n",
       " 4.757728788717941e-07,\n",
       " 0.006596192717552185,\n",
       " 0.9977516531944275,\n",
       " 1.5378403986687772e-05,\n",
       " 2.216952452727128e-06,\n",
       " 0.9078609347343445,\n",
       " 2.9101337872816657e-07,\n",
       " 0.9202219247817993,\n",
       " 2.5297065803897567e-05,\n",
       " 0.11243820935487747,\n",
       " 3.33745219904813e-07,\n",
       " 1.0,\n",
       " 0.9991655349731445,\n",
       " 0.00039719854248687625,\n",
       " 0.0006961075705476105,\n",
       " 8.074380457401276e-05,\n",
       " 0.7765659689903259,\n",
       " 6.398694836207142e-07,\n",
       " 0.036810968071222305,\n",
       " 1.6255897207884118e-05,\n",
       " 6.942981417523697e-05,\n",
       " 0.0024501208681613207,\n",
       " 0.014781462028622627,\n",
       " 2.342966581636574e-06,\n",
       " 0.012484237551689148,\n",
       " 0.9999830722808838,\n",
       " 2.6790987206481987e-09,\n",
       " 0.0009775441139936447,\n",
       " 0.9809845685958862,\n",
       " 4.907426409772597e-05,\n",
       " 2.008109731832519e-06,\n",
       " 0.00029012266895733774,\n",
       " 0.0001226293243234977,\n",
       " 0.028997918590903282,\n",
       " 0.03267168626189232,\n",
       " 0.00022714601072948426,\n",
       " 0.9998766183853149,\n",
       " 0.00012281842646189034,\n",
       " 9.892362129448884e-08,\n",
       " 2.2247040760703385e-06,\n",
       " 0.912648618221283,\n",
       " 4.959449295682816e-09,\n",
       " 2.2004380298312753e-05,\n",
       " 4.1069793041970115e-06,\n",
       " 0.0038449137937277555,\n",
       " 0.940169632434845,\n",
       " 8.448454536846839e-06,\n",
       " 1.5460443592019146e-07,\n",
       " 0.9022098183631897,\n",
       " 0.033458370715379715,\n",
       " 0.9929226636886597,\n",
       " 0.062339067459106445,\n",
       " 0.17776069045066833,\n",
       " 6.517244764836505e-05,\n",
       " 0.00031320590642280877,\n",
       " 0.0004571705649141222,\n",
       " 0.0009470924269407988,\n",
       " 0.03717844560742378,\n",
       " 9.154674240896554e-10,\n",
       " 1.855732080002781e-06,\n",
       " 0.7669201493263245,\n",
       " 9.524045552211646e-09,\n",
       " 0.0013519832864403725,\n",
       " 3.7727866583736613e-05,\n",
       " 0.9993615746498108,\n",
       " 0.9706323742866516,\n",
       " 1.9417194963011752e-08,\n",
       " 6.685812650175649e-07,\n",
       " 0.0182785801589489,\n",
       " 0.00030555686680600047,\n",
       " 0.0002706022060010582,\n",
       " 0.34585830569267273,\n",
       " 7.611649198224768e-05,\n",
       " 0.3337211608886719,\n",
       " 0.0006070871604606509,\n",
       " 0.001428868854418397,\n",
       " 3.2324122003046796e-05,\n",
       " 0.06314098834991455,\n",
       " 0.0001245963212568313,\n",
       " 4.543720137917262e-07,\n",
       " 1.2401452522681211e-06,\n",
       " 0.9992126226425171,\n",
       " 0.7149733901023865,\n",
       " 0.972369909286499,\n",
       " 9.59138196776621e-05,\n",
       " 0.00013118531205691397,\n",
       " 0.36279812455177307,\n",
       " 3.113887032668572e-07,\n",
       " 0.1657702922821045,\n",
       " 3.5520901292329654e-05,\n",
       " 1.7173634958567163e-08,\n",
       " 4.2872139865979264e-11,\n",
       " 0.02329975739121437,\n",
       " 0.0020937705412507057,\n",
       " 7.584427294204943e-06,\n",
       " 5.618656206962669e-09,\n",
       " 0.0002887049631681293,\n",
       " 1.4381380424310919e-06,\n",
       " 0.006491540931165218,\n",
       " 0.016342397779226303,\n",
       " 0.00013685523299500346,\n",
       " 0.000535298662725836,\n",
       " 0.0026412231381982565,\n",
       " 2.7351339667802677e-05,\n",
       " 0.0005281183402985334,\n",
       " 1.4282430349510378e-08,\n",
       " 1.0211203971266514e-06,\n",
       " 0.1260504573583603,\n",
       " 7.400499657528314e-10,\n",
       " 3.3732842297240495e-08,\n",
       " 0.00010960030340356752,\n",
       " 0.006205881480127573,\n",
       " 0.002926513319835067,\n",
       " 1.279715036162088e-07,\n",
       " 0.04067322984337807,\n",
       " 6.079048034735024e-06,\n",
       " 0.5144851207733154,\n",
       " 0.9967671632766724,\n",
       " 7.0405226324510295e-06,\n",
       " 2.0400894129579683e-07,\n",
       " 0.9756734371185303,\n",
       " 0.0023320475593209267,\n",
       " 0.0005598221905529499,\n",
       " 1.0,\n",
       " 9.310330642620102e-05,\n",
       " 0.0010673556244000793,\n",
       " 0.1956360936164856,\n",
       " 2.592674341883594e-08,\n",
       " 2.018464506647888e-08,\n",
       " 5.527454050024971e-06,\n",
       " 1.0,\n",
       " 0.5970546007156372,\n",
       " 5.4638489928038325e-06,\n",
       " 8.104944754450116e-06,\n",
       " 5.200810004879486e-09,\n",
       " 2.655708044585481e-07,\n",
       " 6.954730906727491e-07,\n",
       " 3.139813998132013e-05,\n",
       " 7.378488042775189e-09,\n",
       " 0.06508065015077591,\n",
       " 5.138417691341601e-07,\n",
       " 1.914465741492677e-08,\n",
       " 0.0018753900658339262,\n",
       " 0.9640147686004639,\n",
       " 3.844554885290563e-05,\n",
       " 0.7585476040840149,\n",
       " 0.9892435073852539,\n",
       " 0.030616534873843193,\n",
       " 2.8610118533833884e-05,\n",
       " 0.005353158805519342,\n",
       " 0.9333463311195374,\n",
       " 6.398247205652297e-05,\n",
       " 5.492960553965531e-06,\n",
       " 0.00012626574607566,\n",
       " 0.010051419958472252,\n",
       " 0.008481128141283989,\n",
       " 1.3952541166872834e-07,\n",
       " 3.0183525723259663e-06,\n",
       " 0.047705233097076416,\n",
       " 8.51880770369462e-08,\n",
       " 2.9735306270595174e-06,\n",
       " 1.3722883522859775e-05,\n",
       " 0.001891475054435432,\n",
       " 2.5994982934207655e-05,\n",
       " 9.71661417992209e-09,\n",
       " 0.5354979038238525,\n",
       " 0.19470074772834778,\n",
       " 0.001540982280857861,\n",
       " 0.005860513541847467,\n",
       " 0.00029140672995708883,\n",
       " 0.029042420908808708,\n",
       " 0.0006621734355576336,\n",
       " 0.00036840327084064484,\n",
       " 0.019519846886396408,\n",
       " 0.6782953143119812,\n",
       " 2.0866770000793622e-07,\n",
       " 2.6184527541772695e-06,\n",
       " 0.003491644049063325,\n",
       " 3.2787454983917996e-05,\n",
       " 0.001689985627308488,\n",
       " 0.9999974966049194,\n",
       " 0.0007100113434717059,\n",
       " 0.01483884733170271,\n",
       " 1.4781322533963248e-05,\n",
       " 0.00011931949120480567,\n",
       " 6.280379602685571e-05,\n",
       " 0.005335577763617039,\n",
       " 4.85394450328025e-12,\n",
       " 6.449814691222855e-07,\n",
       " 2.0180985771389715e-08,\n",
       " 1.664211524143866e-08,\n",
       " 0.02099812962114811,\n",
       " 0.0003529922687448561,\n",
       " 2.2309748601401225e-05,\n",
       " 4.629468094208278e-06,\n",
       " 6.122689022447503e-09,\n",
       " 0.33039018511772156,\n",
       " 0.00578303961083293,\n",
       " 1.0,\n",
       " 1.437954210814496e-06,\n",
       " 0.0003356988017912954,\n",
       " 0.0010814350098371506,\n",
       " 1.6750236397911067e-07,\n",
       " 6.937382568139583e-05,\n",
       " 3.084483978454955e-06,\n",
       " 2.625574325065827e-06,\n",
       " 2.3770929669097995e-09,\n",
       " 3.26577918485782e-07,\n",
       " 5.061070282863511e-07,\n",
       " 0.085069939494133,\n",
       " 0.027561655268073082,\n",
       " 0.00015969753440003842,\n",
       " 6.765789294149727e-05,\n",
       " 0.001196782453916967,\n",
       " 3.673851978192033e-08,\n",
       " 0.04707477241754532,\n",
       " 4.2759049392770976e-05,\n",
       " 3.211286809801095e-07,\n",
       " 0.24076204001903534,\n",
       " 4.646083834813908e-05,\n",
       " 0.18803492188453674,\n",
       " 3.432356379562407e-06,\n",
       " 5.0195945178188595e-09,\n",
       " 0.7184647917747498,\n",
       " 1.0,\n",
       " 0.999922513961792,\n",
       " 3.624688361014705e-06,\n",
       " 0.04999347776174545,\n",
       " 0.001948916120454669,\n",
       " 0.00019287191389594227,\n",
       " 0.8777439594268799,\n",
       " 1.1930971595575102e-05,\n",
       " 0.005201409570872784,\n",
       " 0.9099751710891724,\n",
       " 1.0371852710022722e-07,\n",
       " 3.634688425790955e-07,\n",
       " 0.0001374877756461501,\n",
       " 0.22454260289669037,\n",
       " 1.0,\n",
       " 0.017881769686937332,\n",
       " 1.982770614361584e-09,\n",
       " 2.4140173991327174e-05,\n",
       " 6.314670463325456e-05,\n",
       " 0.022774219512939453,\n",
       " 0.03715332970023155,\n",
       " 1.1814920526376227e-06,\n",
       " 7.33469732949743e-07,\n",
       " 0.01105433888733387,\n",
       " 2.2688843159812677e-07,\n",
       " 5.539002927434922e-07,\n",
       " 0.021567948162555695,\n",
       " 2.650475323662249e-07,\n",
       " 8.344693924300373e-06,\n",
       " 0.0033987578935921192,\n",
       " 7.202703500297503e-08,\n",
       " 0.00015188305405899882,\n",
       " 4.655122393160127e-05,\n",
       " 1.8937100321636535e-05,\n",
       " 3.780825500143692e-05,\n",
       " 0.0002307028480572626,\n",
       " 8.789370622253045e-05,\n",
       " 6.554524134116946e-06,\n",
       " 0.002424056176096201,\n",
       " 0.9339191317558289,\n",
       " 0.6177531480789185,\n",
       " 5.475106590324685e-09,\n",
       " 0.9992819428443909,\n",
       " 5.1945171719580685e-08,\n",
       " 0.999988317489624,\n",
       " 4.962668853636387e-08,\n",
       " 2.81191830708849e-07,\n",
       " 0.12871453166007996,\n",
       " 4.3766613089246675e-06,\n",
       " 0.03499149531126022,\n",
       " 9.56923429384915e-10,\n",
       " 0.9541037678718567,\n",
       " 0.3107450306415558,\n",
       " 0.704866886138916,\n",
       " 4.031509433843894e-06,\n",
       " 0.170790895819664,\n",
       " 0.00042101508006453514,\n",
       " 0.0521804615855217,\n",
       " 0.12053745239973068,\n",
       " 0.00013652157213073224,\n",
       " 0.00420409394428134,\n",
       " 4.8375575545378524e-08,\n",
       " 4.696662654168904e-05,\n",
       " 1.3853651559259106e-08,\n",
       " 0.7001024484634399,\n",
       " 0.9975645542144775,\n",
       " 3.2250409276457503e-06,\n",
       " 0.9999054670333862,\n",
       " 1.4004111108079087e-05,\n",
       " 6.6375314418110065e-06,\n",
       " 0.9999957084655762,\n",
       " 0.00022036985319573432,\n",
       " 0.020226549357175827,\n",
       " 0.0047479658387601376,\n",
       " 1.9968868514297355e-07,\n",
       " 6.329131707616398e-08,\n",
       " 2.9143855499569327e-05,\n",
       " 3.88912194466684e-05,\n",
       " 3.543164552866074e-07,\n",
       " 0.993621289730072,\n",
       " 4.207346933071676e-07,\n",
       " 3.838180418824777e-05,\n",
       " 2.431591906992825e-11,\n",
       " 0.9999456405639648,\n",
       " 1.2614394790944061e-06,\n",
       " 0.0005419191438704729,\n",
       " 0.00923097599297762,\n",
       " 6.182717697811313e-07,\n",
       " 0.0003301917458884418,\n",
       " 0.0006817646790295839,\n",
       " 0.005278589203953743,\n",
       " 0.9941680431365967,\n",
       " 1.0,\n",
       " 2.492115299901343e-06,\n",
       " 3.013043681221461e-08,\n",
       " 3.06107033054559e-08,\n",
       " 0.014519400894641876,\n",
       " 5.696405764865631e-07,\n",
       " 4.324450856074691e-06,\n",
       " 0.0027924268506467342,\n",
       " 0.15082737803459167,\n",
       " 0.014761921018362045,\n",
       " 0.6482427716255188,\n",
       " 1.7008675285978825e-06,\n",
       " 5.8252339840692e-08,\n",
       " 1.0,\n",
       " 0.0020757911261171103,\n",
       " 0.28347522020339966,\n",
       " 4.98718344399407e-10,\n",
       " 9.026593033922836e-05,\n",
       " 1.0,\n",
       " 0.0003399182460270822,\n",
       " 0.9999493360519409,\n",
       " 4.890783202426974e-06,\n",
       " 0.14254958927631378,\n",
       " 1.0574700581855723e-06,\n",
       " 0.983159065246582,\n",
       " 0.0018504998879507184,\n",
       " 0.8891451358795166,\n",
       " 1.6370535149690113e-06,\n",
       " 0.007942411117255688,\n",
       " 0.23649558424949646,\n",
       " 1.9329103650989055e-08,\n",
       " 0.10694754868745804,\n",
       " 0.9626821279525757,\n",
       " 5.5840922868810594e-05,\n",
       " 9.725555827344579e-08,\n",
       " 1.329827910012682e-07,\n",
       " 0.0011056546354666352,\n",
       " 1.8349752281210385e-05,\n",
       " 0.0029464163817465305,\n",
       " 0.00045481554116122425,\n",
       " 0.36826014518737793,\n",
       " 1.0170530003961176e-05,\n",
       " 0.07619421184062958,\n",
       " 1.2509048019637703e-08,\n",
       " 0.9929537177085876,\n",
       " 0.09865175932645798,\n",
       " 0.0017683786572888494,\n",
       " 6.2240146689873654e-06,\n",
       " 0.0016162005485966802,\n",
       " 1.5042857237634877e-10,\n",
       " 0.4730885922908783,\n",
       " 0.37448060512542725,\n",
       " 8.57287614053348e-06,\n",
       " 3.681669691335543e-10,\n",
       " 0.0009606480016373098,\n",
       " 4.224371878081001e-06,\n",
       " 0.0072425352409482,\n",
       " 1.5261495718732476e-05,\n",
       " 0.013652288354933262,\n",
       " 0.00044565615826286376,\n",
       " 3.20968174492009e-05,\n",
       " 3.826019796121516e-12,\n",
       " 1.5442715266544838e-06,\n",
       " 0.908709704875946,\n",
       " 0.01849234104156494,\n",
       " 1.0904557257163106e-07,\n",
       " 0.03787129372358322,\n",
       " 1.588871754165666e-07,\n",
       " 0.37462353706359863,\n",
       " 6.981538263062248e-07,\n",
       " 8.41234032122884e-06,\n",
       " 0.3858436942100525,\n",
       " 0.9992794394493103,\n",
       " 0.00036716979229822755,\n",
       " 3.5479317261888355e-08,\n",
       " 0.026258908212184906,\n",
       " 0.08561605960130692,\n",
       " 2.0227119534865778e-07,\n",
       " 0.00045922602294012904,\n",
       " 1.0,\n",
       " 0.01508327852934599,\n",
       " 0.00011791043652920052,\n",
       " 0.00014263219782151282,\n",
       " 0.056722600013017654,\n",
       " 1.8817987168517902e-09,\n",
       " 0.40808045864105225,\n",
       " 2.710872593070235e-07,\n",
       " 0.9721963405609131,\n",
       " 0.0003431494696997106,\n",
       " 1.2751613098771486e-07,\n",
       " 0.0004895061138086021,\n",
       " 6.848710540907632e-07,\n",
       " 1.4899042000138252e-08,\n",
       " 0.7708517909049988,\n",
       " 1.6309264765368425e-06,\n",
       " 0.9954507946968079,\n",
       " 0.6652321219444275,\n",
       " 0.04080307111144066,\n",
       " 0.9999942779541016,\n",
       " 0.0011931423796340823,\n",
       " 7.081368824657375e-09,\n",
       " 0.00010397133155493066,\n",
       " 3.852550989336123e-08,\n",
       " 4.253520455677062e-05,\n",
       " 0.9840831160545349,\n",
       " 6.332452073820605e-08,\n",
       " 0.15879502892494202,\n",
       " 6.71783311645413e-07,\n",
       " 0.9812828302383423,\n",
       " 3.7549182252405444e-07,\n",
       " 0.8885481357574463,\n",
       " 8.978038756879414e-09,\n",
       " 0.8037021160125732,\n",
       " 0.9999998807907104,\n",
       " 4.243764124112204e-05,\n",
       " 5.116781220948496e-09,\n",
       " 0.3820270597934723,\n",
       " 0.9991095662117004,\n",
       " 9.443442650081124e-07,\n",
       " 1.429003759767511e-07,\n",
       " 0.8592365384101868,\n",
       " 0.9999794960021973,\n",
       " 2.659193705767393e-05,\n",
       " 0.0010066311806440353,\n",
       " 1.7002091681206366e-06,\n",
       " 2.1517666937143076e-06,\n",
       " 7.463951988029294e-06,\n",
       " 0.06275173276662827,\n",
       " 0.0009315934148617089,\n",
       " 0.002426169579848647,\n",
       " 3.4662468806345714e-07,\n",
       " 5.0267323636887795e-09,\n",
       " 0.07886073738336563,\n",
       " 4.8413703552796505e-06,\n",
       " 0.9999953508377075,\n",
       " 0.8464770913124084,\n",
       " 3.8220015596834855e-08,\n",
       " 2.9830127459717914e-05,\n",
       " 1.88001649803482e-05,\n",
       " 0.005896114278584719,\n",
       " 2.2657370664092014e-06,\n",
       " 1.2495794976530306e-07,\n",
       " 4.1742520551224516e-09,\n",
       " 5.7263609051005915e-05,\n",
       " 0.0022706177551299334,\n",
       " 0.00022950452694203705,\n",
       " 0.0009856504620984197,\n",
       " 9.520649655314628e-07,\n",
       " 0.9579315781593323,\n",
       " 0.006720397621393204,\n",
       " 0.002920064376667142,\n",
       " 0.41129374504089355,\n",
       " 0.21215039491653442,\n",
       " 0.006494518835097551,\n",
       " 1.2822185908589745e-06,\n",
       " 0.9977363348007202,\n",
       " 2.1630853552778717e-08,\n",
       " 0.6447888612747192,\n",
       " 0.6687856316566467,\n",
       " 4.725739927380346e-06,\n",
       " 0.43590807914733887,\n",
       " 1.0000836603296648e-08,\n",
       " 0.06452534347772598,\n",
       " 4.0259507727569144e-07,\n",
       " 0.02689153142273426,\n",
       " 0.999945878982544,\n",
       " 0.0008620982407592237,\n",
       " 9.228150702256244e-06,\n",
       " 8.679043276060838e-06,\n",
       " 5.572819006260943e-08,\n",
       " 3.275419380166511e-10,\n",
       " 0.7741674780845642,\n",
       " 0.9924860000610352,\n",
       " 0.9984433054924011,\n",
       " 4.0938292755754446e-08,\n",
       " 1.2196252896501392e-07,\n",
       " 0.0005027505685575306,\n",
       " 1.4019460650160909e-06,\n",
       " 3.800319087199355e-11,\n",
       " 0.06348031759262085,\n",
       " 0.00786257442086935,\n",
       " 0.6261169910430908,\n",
       " 0.2978686988353729,\n",
       " 0.04023072496056557,\n",
       " 0.0009058490977622569,\n",
       " 0.0028121955692768097,\n",
       " 0.00010736021067714319,\n",
       " 1.4412145787900954e-07,\n",
       " 0.9645289778709412,\n",
       " 0.002120900433510542,\n",
       " 6.777012458769605e-05,\n",
       " 6.417997155949706e-06,\n",
       " 1.0472340363776311e-05,\n",
       " 0.0012430589413270354,\n",
       " 0.8858311176300049,\n",
       " 7.4752078944584355e-06,\n",
       " 0.7551146745681763,\n",
       " 0.01726243831217289,\n",
       " 6.409715297195362e-06,\n",
       " 0.012245750986039639,\n",
       " 0.014947142452001572,\n",
       " 7.57188558964117e-07,\n",
       " 2.5411928117335947e-09,\n",
       " 0.017670534551143646,\n",
       " 0.20171001553535461,\n",
       " 0.6761857271194458,\n",
       " 0.9902468919754028,\n",
       " 0.0001876798050943762,\n",
       " 1.3862289733879152e-06,\n",
       " 0.6742314696311951,\n",
       " 0.3527921140193939,\n",
       " 6.24203408960966e-08,\n",
       " 0.18770724534988403,\n",
       " 8.469251042697579e-06,\n",
       " 0.037343475967645645,\n",
       " 7.112513412721455e-05,\n",
       " 0.9733206629753113,\n",
       " 2.720050133575569e-06,\n",
       " 6.452829666159232e-07,\n",
       " 0.031323373317718506,\n",
       " 0.0010489808628335595,\n",
       " 0.06795725971460342,\n",
       " 1.703870378122474e-10,\n",
       " 0.0006378985126502812,\n",
       " 0.08020846545696259,\n",
       " 0.5479649305343628,\n",
       " 0.000193581247003749,\n",
       " 3.312755225692854e-08,\n",
       " 3.4015883443316852e-09,\n",
       " 3.9381383487580024e-08,\n",
       " 0.015570727176964283,\n",
       " 0.003323678392916918,\n",
       " 0.7198885083198547,\n",
       " 1.0181671314057894e-05,\n",
       " 1.0,\n",
       " 0.9999597072601318,\n",
       " 1.3360154760277965e-08,\n",
       " 0.992706835269928,\n",
       " 3.1537737699149915e-11,\n",
       " 0.00010989416477968916,\n",
       " 0.0008932073251344264,\n",
       " 2.0849299176006753e-08,\n",
       " 4.54851445397253e-08,\n",
       " 0.026467813178896904,\n",
       " 0.01681305468082428,\n",
       " 0.7441722750663757,\n",
       " 0.03400218114256859,\n",
       " 0.0001743841276038438,\n",
       " 0.05263540521264076,\n",
       " 0.00043483934132382274,\n",
       " 0.017150485888123512,\n",
       " 0.00021082133753225207,\n",
       " 0.9999958276748657,\n",
       " 0.9907439351081848,\n",
       " 0.8826994299888611,\n",
       " 0.02932862564921379,\n",
       " 0.0009082898031920195,\n",
       " 0.34609049558639526,\n",
       " 0.0003831359790638089,\n",
       " 0.0020391750149428844,\n",
       " 6.220893737918232e-06,\n",
       " 2.2717113523640364e-08,\n",
       " 1.9860319298459217e-05,\n",
       " 2.5267586352129e-06,\n",
       " 0.00021528660727199167,\n",
       " 4.5855986172682606e-06,\n",
       " 1.495955359587242e-08,\n",
       " 0.14420345425605774,\n",
       " 2.060974537698712e-07,\n",
       " 0.000196043896721676,\n",
       " 0.019086327403783798,\n",
       " 2.2719708795193583e-05,\n",
       " 7.126055152184563e-06,\n",
       " 1.0,\n",
       " 0.738222599029541,\n",
       " 0.480133056640625,\n",
       " 0.6628612875938416,\n",
       " 3.711348384172197e-08,\n",
       " 7.157645995903295e-07,\n",
       " 1.4624133655161131e-06,\n",
       " 7.898107128312404e-07,\n",
       " 0.0001305658370256424,\n",
       " 0.0007027036044746637,\n",
       " 0.0012674604076892138,\n",
       " 0.9994381070137024,\n",
       " 3.5005297149837133e-07,\n",
       " 1.1917171693909268e-09,\n",
       " 0.00013853213749825954,\n",
       " 7.883216312620789e-06,\n",
       " 2.419498014205601e-05,\n",
       " 0.016708040609955788,\n",
       " 0.9682203531265259,\n",
       " 0.000557966239284724,\n",
       " 0.9999966621398926,\n",
       " 9.941005555447191e-05,\n",
       " 0.0009274609619751573,\n",
       " 5.260843636278878e-07,\n",
       " 0.0016379349399358034,\n",
       " 0.0186458770185709,\n",
       " 6.616749459453786e-08,\n",
       " 5.6738306739134714e-05,\n",
       " 6.270971789490432e-05,\n",
       " 6.191879037942272e-06,\n",
       " 0.9995878338813782,\n",
       " 0.00010117836063727736,\n",
       " 7.064344390528277e-05,\n",
       " 0.003479626029729843,\n",
       " 0.9780063629150391,\n",
       " 2.301692170192382e-08,\n",
       " 5.595083285570013e-10,\n",
       " 0.21988339722156525,\n",
       " 0.9905851483345032,\n",
       " 3.518952382819407e-07,\n",
       " 0.20622070133686066,\n",
       " 0.38125377893447876,\n",
       " 0.0036787257995456457,\n",
       " 1.598495487087348e-07,\n",
       " 0.9666028618812561,\n",
       " 2.955425543404999e-06,\n",
       " 6.309542368398979e-05,\n",
       " 2.7364348564873353e-09,\n",
       " 0.7256630063056946,\n",
       " 0.0009448606870137155,\n",
       " 0.8531277179718018,\n",
       " 0.0004513964813668281,\n",
       " 6.61941448925063e-05,\n",
       " 0.9999700784683228,\n",
       " 0.0018479053396731615,\n",
       " 0.0011781647335737944,\n",
       " 9.150681989922305e-07,\n",
       " 0.0004038711776956916,\n",
       " 0.7922942042350769,\n",
       " 0.020859230309724808,\n",
       " 2.531152858864516e-06,\n",
       " 9.740917448652908e-06,\n",
       " 3.867824943881715e-06,\n",
       " 0.00014124195149634033,\n",
       " 0.00045903344289399683,\n",
       " 7.907098188297823e-05,\n",
       " 1.6542479670533794e-06,\n",
       " 1.8427332179271616e-05,\n",
       " 2.2507290850626305e-05,\n",
       " 0.015349824912846088,\n",
       " 0.9278019070625305,\n",
       " 0.04211141914129257,\n",
       " 0.0011157442349940538,\n",
       " 0.03896506875753403,\n",
       " 0.00013230463082436472,\n",
       " 0.6318073272705078,\n",
       " 0.10867871344089508,\n",
       " 0.5843712091445923,\n",
       " 0.09937354922294617,\n",
       " 1.0,\n",
       " 6.386513859979459e-07,\n",
       " 1.0,\n",
       " 0.0042904275469481945,\n",
       " 0.002260012784972787,\n",
       " 2.412497757120491e-08,\n",
       " 0.987996518611908,\n",
       " 0.001079689129255712,\n",
       " 0.019935378804802895,\n",
       " 1.0,\n",
       " 0.004210438579320908,\n",
       " 1.4058251508686226e-05,\n",
       " 5.6592187320347875e-05,\n",
       " 0.9895066618919373,\n",
       " 0.06302712857723236,\n",
       " 0.29635584354400635,\n",
       " 1.7223983377334662e-05,\n",
       " 0.0019059260375797749,\n",
       " 2.6226011868857313e-06,\n",
       " 2.6451070311850344e-07,\n",
       " 0.0005681173643097281,\n",
       " 0.9262545108795166,\n",
       " 1.7039491240211646e-06,\n",
       " 0.0004522527160588652,\n",
       " 8.621721114820957e-09,\n",
       " 0.09522844105958939,\n",
       " 0.6183051466941833,\n",
       " 9.784379653865471e-05,\n",
       " 0.3952946662902832,\n",
       " 2.138693844244699e-06,\n",
       " 0.00034515216248109937,\n",
       " 5.7361990911886096e-05,\n",
       " 5.32660386909356e-08,\n",
       " 0.000782273942604661,\n",
       " 4.016186849753467e-08,\n",
       " 0.010442867875099182,\n",
       " 5.552299597866295e-08,\n",
       " 3.6377379728946835e-05,\n",
       " 0.9999997615814209,\n",
       " 2.0640507614189119e-07,\n",
       " 0.14821423590183258,\n",
       " 0.00023883595713414252,\n",
       " 7.864990152484097e-07,\n",
       " 0.9999071359634399,\n",
       " 0.06272996962070465,\n",
       " 0.9426326751708984,\n",
       " 0.9997182488441467,\n",
       " 0.3093944489955902,\n",
       " 4.3634969188133255e-05,\n",
       " 0.13610121607780457,\n",
       " 0.008967036381363869,\n",
       " 0.00011880382953677326,\n",
       " 0.999991774559021,\n",
       " 0.02479834482073784,\n",
       " 0.008446009829640388,\n",
       " 0.876150906085968,\n",
       " 0.008636466227471828,\n",
       " 1.2421798601280898e-05,\n",
       " 0.9903900623321533,\n",
       " 3.9999402360990644e-05,\n",
       " 1.0,\n",
       " 9.358467650599778e-05,\n",
       " 0.7261496186256409,\n",
       " 0.0015690671280026436,\n",
       " 1.1647243809420615e-06,\n",
       " 0.7131655812263489,\n",
       " 0.01109858974814415,\n",
       " 0.9999902248382568,\n",
       " 4.689638122279405e-10,\n",
       " 9.066923212230904e-09,\n",
       " 0.009432635270059109,\n",
       " 0.001135577098466456,\n",
       " 0.004840257111936808,\n",
       " 0.0765499472618103,\n",
       " 0.005208727903664112,\n",
       " 5.411786219156056e-08,\n",
       " 0.1419617086648941,\n",
       " 0.049646858125925064,\n",
       " 0.0020850016735494137,\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
